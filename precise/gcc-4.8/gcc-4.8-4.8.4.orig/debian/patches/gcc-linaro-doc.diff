# DP: Changes for the Linaro 4.8-2015.02 release (documentation).

--- a/src/gcc/doc/extend.texi
+++ b/src/gcc/doc/extend.texi
@@ -8794,6 +8794,7 @@
 * Alpha Built-in Functions::
 * ARM iWMMXt Built-in Functions::
 * ARM NEON Intrinsics::
+* ARM ACLE Intrinsics::
 * AVR Built-in Functions::
 * Blackfin Built-in Functions::
 * FR-V Built-in Functions::
@@ -9060,6 +9061,14 @@
 
 @include arm-neon-intrinsics.texi
 
+@node ARM ACLE Intrinsics
+@subsection ARM ACLE Intrinsics
+
+These built-in intrinsics for the ARMv8-A CRC32 extension are available when
+the @option{-march=armv8-a+crc} switch is used:
+
+@include arm-acle-intrinsics.texi
+
 @node AVR Built-in Functions
 @subsection AVR Built-in Functions
 
--- a/src/gcc/doc/arm-acle-intrinsics.texi
+++ b/src/gcc/doc/arm-acle-intrinsics.texi
@@ -0,0 +1,55 @@
+@c Copyright (C) 2013-2014 Free Software Foundation, Inc.
+@c This is part of the GCC manual.
+@c For copying conditions, see the file gcc.texi.
+
+@subsubsection CRC32 intrinsics
+
+@itemize @bullet
+@item uint32_t __crc32b (uint32_t, uint8_t)
+@*@emph{Form of expected instruction(s):} @code{crc32b @var{r0}, @var{r0}, @var{r0}}
+@end itemize
+
+
+@itemize @bullet
+@item uint32_t __crc32h (uint32_t, uint16_t)
+@*@emph{Form of expected instruction(s):} @code{crc32h @var{r0}, @var{r0}, @var{r0}}
+@end itemize
+
+
+@itemize @bullet
+@item uint32_t __crc32w (uint32_t, uint32_t)
+@*@emph{Form of expected instruction(s):} @code{crc32w @var{r0}, @var{r0}, @var{r0}}
+@end itemize
+
+
+@itemize @bullet
+@item uint32_t __crc32d (uint32_t, uint64_t)
+@*@emph{Form of expected instruction(s):} Two @code{crc32w @var{r0}, @var{r0}, @var{r0}}
+instructions for AArch32. One @code{crc32w @var{w0}, @var{w0}, @var{x0}} instruction for
+AArch64.
+@end itemize
+
+@itemize @bullet
+@item uint32_t __crc32cb (uint32_t, uint8_t)
+@*@emph{Form of expected instruction(s):} @code{crc32cb @var{r0}, @var{r0}, @var{r0}}
+@end itemize
+
+
+@itemize @bullet
+@item uint32_t __crc32ch (uint32_t, uint16_t)
+@*@emph{Form of expected instruction(s):} @code{crc32ch @var{r0}, @var{r0}, @var{r0}}
+@end itemize
+
+
+@itemize @bullet
+@item uint32_t __crc32cw (uint32_t, uint32_t)
+@*@emph{Form of expected instruction(s):} @code{crc32cw @var{r0}, @var{r0}, @var{r0}}
+@end itemize
+
+
+@itemize @bullet
+@item uint32_t __crc32cd (uint32_t, uint64_t)
+@*@emph{Form of expected instruction(s):} Two @code{crc32cw @var{r0}, @var{r0}, @var{r0}}
+instructions for AArch32. One @code{crc32cw @var{w0}, @var{w0}, @var{x0}} instruction for
+AArch64.
+@end itemize
--- a/src/gcc/doc/tm.texi
+++ b/src/gcc/doc/tm.texi
@@ -10925,10 +10925,18 @@
 @samp{TARGET_INIT_BUILTINS}.  @var{fndecl} is the declaration of the
 built-in function.  @var{n_args} is the number of arguments passed to
 the function; the arguments themselves are pointed to by @var{argp}.
-The result is another tree containing a simplified expression for the
-call's result.  If @var{ignore} is true the value will be ignored.
+The result is another tree, valid for both GIMPLE and GENERIC,
+containing a simplified expression for the call's result.  If
+@var{ignore} is true the value will be ignored.
 @end deftypefn
 
+@deftypefn {Target Hook} bool TARGET_GIMPLE_FOLD_BUILTIN (gimple_stmt_iterator *@var{gsi})
+Fold a call to a machine specific built-in function that was set up
+by @samp{TARGET_INIT_BUILTINS}.  @var{gsi} points to the gimple
+statement holding the function call.  Returns true if any change
+was made to the GIMPLE stream.
+@end deftypefn
+
 @deftypefn {Target Hook} int TARGET_COMPARE_VERSION_PRIORITY (tree @var{decl1}, tree @var{decl2})
 This hook is used to compare the target attributes in two functions to
 determine which function's features get higher priority.  This is used
--- a/src/gcc/doc/tm.texi.in
+++ b/src/gcc/doc/tm.texi.in
@@ -10771,10 +10771,13 @@
 @samp{TARGET_INIT_BUILTINS}.  @var{fndecl} is the declaration of the
 built-in function.  @var{n_args} is the number of arguments passed to
 the function; the arguments themselves are pointed to by @var{argp}.
-The result is another tree containing a simplified expression for the
-call's result.  If @var{ignore} is true the value will be ignored.
+The result is another tree, valid for both GIMPLE and GENERIC,
+containing a simplified expression for the call's result.  If
+@var{ignore} is true the value will be ignored.
 @end deftypefn
 
+@hook TARGET_GIMPLE_FOLD_BUILTIN
+
 @hook TARGET_COMPARE_VERSION_PRIORITY
 This hook is used to compare the target attributes in two functions to
 determine which function's features get higher priority.  This is used
--- a/src/gcc/doc/invoke.texi
+++ b/src/gcc/doc/invoke.texi
@@ -418,7 +418,7 @@
 -ftree-parallelize-loops=@var{n} -ftree-pre -ftree-partial-pre -ftree-pta @gol
 -ftree-reassoc -ftree-sink -ftree-slsr -ftree-sra @gol
 -ftree-switch-conversion -ftree-tail-merge @gol
--ftree-ter -ftree-vect-loop-version -ftree-vectorize -ftree-vrp @gol
+-ftree-ter -ftree-vectorize -ftree-vrp @gol
 -funit-at-a-time -funroll-all-loops -funroll-loops @gol
 -funsafe-loop-optimizations -funsafe-math-optimizations -funswitch-loops @gol
 -fvariable-expansion-in-unroller -fvect-cost-model -fvpt -fweb @gol
@@ -511,7 +511,9 @@
 -mtp=@var{name} -mtls-dialect=@var{dialect} @gol
 -mword-relocations @gol
 -mfix-cortex-m3-ldrd @gol
--munaligned-access}
+-munaligned-access @gol
+-mneon-for-64bits @gol
+-mrestrict-it}
 
 @emph{AVR Options}
 @gccoptlist{-mmcu=@var{mcu} -maccumulate-args -mbranch-cost=@var{cost} @gol
@@ -6606,7 +6608,7 @@
 @option{-Os} disables the following optimization flags:
 @gccoptlist{-falign-functions  -falign-jumps  -falign-loops @gol
 -falign-labels  -freorder-blocks  -freorder-blocks-and-partition @gol
--fprefetch-loop-arrays  -ftree-vect-loop-version}
+-fprefetch-loop-arrays}
 
 @item -Ofast
 @opindex Ofast
@@ -7847,19 +7849,20 @@
 Perform basic block vectorization on trees. This flag is enabled by default at
 @option{-O3} and when @option{-ftree-vectorize} is enabled.
 
-@item -ftree-vect-loop-version
-@opindex ftree-vect-loop-version
-Perform loop versioning when doing loop vectorization on trees.  When a loop
-appears to be vectorizable except that data alignment or data dependence cannot
-be determined at compile time, then vectorized and non-vectorized versions of
-the loop are generated along with run-time checks for alignment or dependence
-to control which version is executed.  This option is enabled by default
-except at level @option{-Os} where it is disabled.
-
-@item -fvect-cost-model
+@item -fvect-cost-model=@var{model}
 @opindex fvect-cost-model
-Enable cost model for vectorization.  This option is enabled by default at
-@option{-O3}.
+Alter the cost model used for vectorization.  The @var{model} argument
+should be one of @code{unlimited}, @code{dynamic} or @code{cheap}.
+With the @code{unlimited} model the vectorized code-path is assumed
+to be profitable while with the @code{dynamic} model a runtime check
+will guard the vectorized code-path to enable it only for iteration
+counts that will likely execute faster than when executing the original
+scalar loop.  The @code{cheap} model will disable vectorization of
+loops where doing so would be cost prohibitive for example due to
+required runtime checks for data dependence or alignment but otherwise
+is equal to the @code{dynamic} model.
+The default cost model depends on other optimization flags and is
+either @code{dynamic} or @code{cheap}.
 
 @item -ftree-vrp
 @opindex ftree-vrp
@@ -9255,14 +9258,16 @@
 
 @item vect-max-version-for-alignment-checks
 The maximum number of run-time checks that can be performed when
-doing loop versioning for alignment in the vectorizer.  See option
-@option{-ftree-vect-loop-version} for more information.
+doing loop versioning for alignment in the vectorizer. 
 
 @item vect-max-version-for-alias-checks
 The maximum number of run-time checks that can be performed when
-doing loop versioning for alias in the vectorizer.  See option
-@option{-ftree-vect-loop-version} for more information.
+doing loop versioning for alias in the vectorizer. 
 
+@item vect-max-peeling-for-alignment
+The maximum number of loop peels to enhance access alignment
+for vectorizer. Value -1 means 'no limit'.
+
 @item max-iterations-to-track
 The maximum number of iterations of a loop the brute-force algorithm
 for analysis of the number of iterations of the loop tries to evaluate.
@@ -10990,6 +10995,8 @@
 the following:
 
 @table @samp
+@item crc
+Enable CRC extension.
 @item crypto
 Enable Crypto extension.  This implies Advanced SIMD is enabled.
 @item fp
@@ -11276,9 +11283,12 @@
 @samp{armv6}, @samp{armv6j},
 @samp{armv6t2}, @samp{armv6z}, @samp{armv6zk}, @samp{armv6-m},
 @samp{armv7}, @samp{armv7-a}, @samp{armv7-r}, @samp{armv7-m}, @samp{armv7e-m}
-@samp{armv8-a},
+@samp{armv8-a}, @samp{armv8-a+crc},
 @samp{iwmmxt}, @samp{iwmmxt2}, @samp{ep9312}.
 
+@option{-march=armv8-a+crc} enables code generation for the ARMv8-A
+architecture together with the optional CRC32 extensions.
+
 @option{-march=native} causes the compiler to auto-detect the architecture
 of the build computer.  At present, this feature is only supported on
 GNU/Linux, and not all architectures are recognized.  If the auto-detect
@@ -11308,8 +11318,8 @@
 @samp{arm1136j-s}, @samp{arm1136jf-s}, @samp{mpcore}, @samp{mpcorenovfp},
 @samp{arm1156t2-s}, @samp{arm1156t2f-s}, @samp{arm1176jz-s}, @samp{arm1176jzf-s},
 @samp{cortex-a5}, @samp{cortex-a7}, @samp{cortex-a8}, @samp{cortex-a9}, 
-@samp{cortex-a15}, @samp{cortex-r4}, @samp{cortex-r4f}, @samp{cortex-r5},
-@samp{cortex-m4}, @samp{cortex-m3},
+@samp{cortex-a15}, @samp{cortex-a53}, @samp{cortex-r4}, @samp{cortex-r4f},
+@samp{cortex-r5}, @samp{cortex-r7}, @samp{cortex-m4}, @samp{cortex-m3},
 @samp{cortex-m1},
 @samp{cortex-m0},
 @samp{cortex-m0plus},
@@ -11556,6 +11566,17 @@
 preprocessor symbol @code{__ARM_FEATURE_UNALIGNED} will also be
 defined.
 
+@item -mneon-for-64bits
+@opindex mneon-for-64bits
+Enables using Neon to handle scalar 64-bits operations. This is
+disabled by default since the cost of moving data from core registers
+to Neon is high.
+
+@item -mrestrict-it
+@opindex mrestrict-it
+Restricts generation of IT blocks to conform to the rules of ARMv8.
+IT blocks can only contain a single 16-bit instruction from a select
+set of instructions. This option is on by default for ARMv8 Thumb mode.
 @end table
 
 @node AVR Options
--- a/src/gcc/doc/arm-neon-intrinsics.texi
+++ b/src/gcc/doc/arm-neon-intrinsics.texi
@@ -4079,6 +4079,12 @@
 @subsubsection Vector shift right and insert
 
 @itemize @bullet
+@item poly64x1_t vsri_n_p64 (poly64x1_t, poly64x1_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vsri.64 @var{d0}, @var{d0}, #@var{0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x2_t vsri_n_u32 (uint32x2_t, uint32x2_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vsri.32 @var{d0}, @var{d0}, #@var{0}}
 @end itemize
@@ -4139,6 +4145,12 @@
 
 
 @itemize @bullet
+@item poly64x2_t vsriq_n_p64 (poly64x2_t, poly64x2_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vsri.64 @var{q0}, @var{q0}, #@var{0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x4_t vsriq_n_u32 (uint32x4_t, uint32x4_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vsri.32 @var{q0}, @var{q0}, #@var{0}}
 @end itemize
@@ -4203,6 +4215,12 @@
 @subsubsection Vector shift left and insert
 
 @itemize @bullet
+@item poly64x1_t vsli_n_p64 (poly64x1_t, poly64x1_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vsli.64 @var{d0}, @var{d0}, #@var{0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x2_t vsli_n_u32 (uint32x2_t, uint32x2_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vsli.32 @var{d0}, @var{d0}, #@var{0}}
 @end itemize
@@ -4263,6 +4281,12 @@
 
 
 @itemize @bullet
+@item poly64x2_t vsliq_n_p64 (poly64x2_t, poly64x2_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vsli.64 @var{q0}, @var{q0}, #@var{0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x4_t vsliq_n_u32 (uint32x4_t, uint32x4_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vsli.32 @var{q0}, @var{q0}, #@var{0}}
 @end itemize
@@ -5071,6 +5095,11 @@
 @subsubsection Create vector from literal bit pattern
 
 @itemize @bullet
+@item poly64x1_t vcreate_p64 (uint64_t)
+@end itemize
+
+
+@itemize @bullet
 @item uint32x2_t vcreate_u32 (uint64_t)
 @end itemize
 
@@ -5184,6 +5213,11 @@
 
 
 @itemize @bullet
+@item poly64x1_t vdup_n_p64 (poly64_t)
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1_t vdup_n_u64 (uint64_t)
 @end itemize
 
@@ -5194,6 +5228,11 @@
 
 
 @itemize @bullet
+@item poly64x2_t vdupq_n_p64 (poly64_t)
+@end itemize
+
+
+@itemize @bullet
 @item uint32x4_t vdupq_n_u32 (uint32_t)
 @*@emph{Form of expected instruction(s):} @code{vdup.32 @var{q0}, @var{r0}}
 @end itemize
@@ -5440,6 +5479,11 @@
 
 
 @itemize @bullet
+@item poly64x1_t vdup_lane_p64 (poly64x1_t, const int)
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1_t vdup_lane_u64 (uint64x1_t, const int)
 @end itemize
 
@@ -5504,6 +5548,11 @@
 
 
 @itemize @bullet
+@item poly64x2_t vdupq_lane_p64 (poly64x1_t, const int)
+@end itemize
+
+
+@itemize @bullet
 @item uint64x2_t vdupq_lane_u64 (uint64x1_t, const int)
 @end itemize
 
@@ -5518,6 +5567,11 @@
 @subsubsection Combining vectors
 
 @itemize @bullet
+@item poly64x2_t vcombine_p64 (poly64x1_t, poly64x1_t)
+@end itemize
+
+
+@itemize @bullet
 @item uint32x4_t vcombine_u32 (uint32x2_t, uint32x2_t)
 @end itemize
 
@@ -5577,6 +5631,11 @@
 @subsubsection Splitting vectors
 
 @itemize @bullet
+@item poly64x1_t vget_high_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
 @item uint32x2_t vget_high_u32 (uint32x4_t)
 @end itemize
 
@@ -5686,6 +5745,11 @@
 
 
 @itemize @bullet
+@item poly64x1_t vget_low_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1_t vget_low_u64 (uint64x2_t)
 @end itemize
 
@@ -5748,6 +5812,18 @@
 
 
 @itemize @bullet
+@item float16x4_t vcvt_f16_f32 (float32x4_t)
+@*@emph{Form of expected instruction(s):} @code{vcvt.f16.f32 @var{d0}, @var{q0}}
+@end itemize
+
+
+@itemize @bullet
+@item float32x4_t vcvt_f32_f16 (float16x4_t)
+@*@emph{Form of expected instruction(s):} @code{vcvt.f32.f16 @var{q0}, @var{d0}}
+@end itemize
+
+
+@itemize @bullet
 @item float32x2_t vcvt_n_f32_u32 (uint32x2_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vcvt.f32.u32 @var{d0}, @var{d0}, #@var{0}}
 @end itemize
@@ -6806,6 +6882,12 @@
 @subsubsection Vector extract
 
 @itemize @bullet
+@item poly64x1_t vext_p64 (poly64x1_t, poly64x1_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vext.64 @var{d0}, @var{d0}, @var{d0}, #@var{0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x2_t vext_u32 (uint32x2_t, uint32x2_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vext.32 @var{d0}, @var{d0}, @var{d0}, #@var{0}}
 @end itemize
@@ -6872,6 +6954,12 @@
 
 
 @itemize @bullet
+@item poly64x2_t vextq_p64 (poly64x2_t, poly64x2_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vext.64 @var{q0}, @var{q0}, @var{q0}, #@var{0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x4_t vextq_u32 (uint32x4_t, uint32x4_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vext.32 @var{q0}, @var{q0}, @var{q0}, #@var{0}}
 @end itemize
@@ -7162,6 +7250,12 @@
 @subsubsection Bit selection
 
 @itemize @bullet
+@item poly64x1_t vbsl_p64 (uint64x1_t, poly64x1_t, poly64x1_t)
+@*@emph{Form of expected instruction(s):} @code{vbsl @var{d0}, @var{d0}, @var{d0}} @emph{or} @code{vbit @var{d0}, @var{d0}, @var{d0}} @emph{or} @code{vbif @var{d0}, @var{d0}, @var{d0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x2_t vbsl_u32 (uint32x2_t, uint32x2_t, uint32x2_t)
 @*@emph{Form of expected instruction(s):} @code{vbsl @var{d0}, @var{d0}, @var{d0}} @emph{or} @code{vbit @var{d0}, @var{d0}, @var{d0}} @emph{or} @code{vbif @var{d0}, @var{d0}, @var{d0}}
 @end itemize
@@ -7228,6 +7322,12 @@
 
 
 @itemize @bullet
+@item poly64x2_t vbslq_p64 (uint64x2_t, poly64x2_t, poly64x2_t)
+@*@emph{Form of expected instruction(s):} @code{vbsl @var{q0}, @var{q0}, @var{q0}} @emph{or} @code{vbit @var{q0}, @var{q0}, @var{q0}} @emph{or} @code{vbif @var{q0}, @var{q0}, @var{q0}}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x4_t vbslq_u32 (uint32x4_t, uint32x4_t, uint32x4_t)
 @*@emph{Form of expected instruction(s):} @code{vbsl @var{q0}, @var{q0}, @var{q0}} @emph{or} @code{vbit @var{q0}, @var{q0}, @var{q0}} @emph{or} @code{vbif @var{q0}, @var{q0}, @var{q0}}
 @end itemize
@@ -7634,6 +7734,12 @@
 @subsubsection Element/structure loads, VLD1 variants
 
 @itemize @bullet
+@item poly64x1_t vld1_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x2_t vld1_u32 (const uint32_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.32 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -7700,6 +7806,12 @@
 
 
 @itemize @bullet
+@item poly64x2_t vld1q_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint32x4_t vld1q_u32 (const uint32_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.32 @{@var{d0}, @var{d1}@}, [@var{r0}]}
 @end itemize
@@ -7820,6 +7932,12 @@
 
 
 @itemize @bullet
+@item poly64x1_t vld1_lane_p64 (const poly64_t *, poly64x1_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1_t vld1_lane_u64 (const uint64_t *, uint64x1_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -7886,6 +8004,12 @@
 
 
 @itemize @bullet
+@item poly64x2_t vld1q_lane_p64 (const poly64_t *, poly64x2_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x2_t vld1q_lane_u64 (const uint64_t *, uint64x2_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -7952,6 +8076,12 @@
 
 
 @itemize @bullet
+@item poly64x1_t vld1_dup_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1_t vld1_dup_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -8018,6 +8148,12 @@
 
 
 @itemize @bullet
+@item poly64x2_t vld1q_dup_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x2_t vld1q_dup_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -8034,6 +8170,12 @@
 @subsubsection Element/structure stores, VST1 variants
 
 @itemize @bullet
+@item void vst1_p64 (poly64_t *, poly64x1_t)
+@*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item void vst1_u32 (uint32_t *, uint32x2_t)
 @*@emph{Form of expected instruction(s):} @code{vst1.32 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -8100,6 +8242,12 @@
 
 
 @itemize @bullet
+@item void vst1q_p64 (poly64_t *, poly64x2_t)
+@*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item void vst1q_u32 (uint32_t *, uint32x4_t)
 @*@emph{Form of expected instruction(s):} @code{vst1.32 @{@var{d0}, @var{d1}@}, [@var{r0}]}
 @end itemize
@@ -8220,6 +8368,12 @@
 
 
 @itemize @bullet
+@item void vst1_lane_p64 (poly64_t *, poly64x1_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item void vst1_lane_s64 (int64_t *, int64x1_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -8286,6 +8440,12 @@
 
 
 @itemize @bullet
+@item void vst1q_lane_p64 (poly64_t *, poly64x2_t, const int)
+@*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item void vst1q_lane_s64 (int64_t *, int64x2_t, const int)
 @*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}@}, [@var{r0}]}
 @end itemize
@@ -8356,6 +8516,12 @@
 
 
 @itemize @bullet
+@item poly64x1x2_t vld2_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1x2_t vld2_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
 @end itemize
@@ -8566,6 +8732,12 @@
 
 
 @itemize @bullet
+@item poly64x1x2_t vld2_dup_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1x2_t vld2_dup_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
 @end itemize
@@ -8636,6 +8808,12 @@
 
 
 @itemize @bullet
+@item void vst2_p64 (poly64_t *, poly64x1x2_t)
+@*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item void vst2_u64 (uint64_t *, uint64x1x2_t)
 @*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}, @var{d1}@}, [@var{r0}]}
 @end itemize
@@ -8850,6 +9028,12 @@
 
 
 @itemize @bullet
+@item poly64x1x3_t vld3_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1x3_t vld3_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}@}, [@var{r0}]}
 @end itemize
@@ -9060,6 +9244,12 @@
 
 
 @itemize @bullet
+@item poly64x1x3_t vld3_dup_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1x3_t vld3_dup_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}@}, [@var{r0}]}
 @end itemize
@@ -9130,6 +9320,12 @@
 
 
 @itemize @bullet
+@item void vst3_p64 (poly64_t *, poly64x1x3_t)
+@*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item void vst3_u64 (uint64_t *, uint64x1x3_t)
 @*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
 @end itemize
@@ -9344,6 +9540,12 @@
 
 
 @itemize @bullet
+@item poly64x1x4_t vld4_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1x4_t vld4_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
 @end itemize
@@ -9554,6 +9756,12 @@
 
 
 @itemize @bullet
+@item poly64x1x4_t vld4_dup_p64 (const poly64_t *)
+@*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item uint64x1x4_t vld4_dup_u64 (const uint64_t *)
 @*@emph{Form of expected instruction(s):} @code{vld1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
 @end itemize
@@ -9624,6 +9832,12 @@
 
 
 @itemize @bullet
+@item void vst4_p64 (poly64_t *, poly64x1x4_t)
+@*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
+@end itemize
+
+
+@itemize @bullet
 @item void vst4_u64 (uint64_t *, uint64x1x4_t)
 @*@emph{Form of expected instruction(s):} @code{vst1.64 @{@var{d0}, @var{d1}, @var{d2}, @var{d3}@}, [@var{r0}]}
 @end itemize
@@ -10274,27 +10488,27 @@
 @subsubsection Reinterpret casts
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_u32 (uint32x2_t)
+@item poly8x8_t vreinterpret_p8_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_u16 (uint16x4_t)
+@item poly8x8_t vreinterpret_p8_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_u8 (uint8x8_t)
+@item poly8x8_t vreinterpret_p8_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_s32 (int32x2_t)
+@item poly8x8_t vreinterpret_p8_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_s16 (int16x4_t)
+@item poly8x8_t vreinterpret_p8_u64 (uint64x1_t)
 @end itemize
 
 
@@ -10304,952 +10518,1317 @@
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_u64 (uint64x1_t)
+@item poly8x8_t vreinterpret_p8_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_s64 (int64x1_t)
+@item poly8x8_t vreinterpret_p8_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_f32 (float32x2_t)
+@item poly8x8_t vreinterpret_p8_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x8_t vreinterpret_p8_p16 (poly16x4_t)
+@item poly8x8_t vreinterpret_p8_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_u32 (uint32x4_t)
+@item poly8x8_t vreinterpret_p8_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_u16 (uint16x8_t)
+@item poly16x4_t vreinterpret_p16_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_u8 (uint8x16_t)
+@item poly16x4_t vreinterpret_p16_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_s32 (int32x4_t)
+@item poly16x4_t vreinterpret_p16_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_s16 (int16x8_t)
+@item poly16x4_t vreinterpret_p16_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_s8 (int8x16_t)
+@item poly16x4_t vreinterpret_p16_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_u64 (uint64x2_t)
+@item poly16x4_t vreinterpret_p16_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_s64 (int64x2_t)
+@item poly16x4_t vreinterpret_p16_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_f32 (float32x4_t)
+@item poly16x4_t vreinterpret_p16_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly8x16_t vreinterpretq_p8_p16 (poly16x8_t)
+@item poly16x4_t vreinterpret_p16_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
+@item poly16x4_t vreinterpret_p16_u16 (uint16x4_t)
+@end itemize
+
+
+@itemize @bullet
 @item poly16x4_t vreinterpret_p16_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_u16 (uint16x4_t)
+@item float32x2_t vreinterpret_f32_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_u8 (uint8x8_t)
+@item float32x2_t vreinterpret_f32_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_s32 (int32x2_t)
+@item float32x2_t vreinterpret_f32_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_s16 (int16x4_t)
+@item float32x2_t vreinterpret_f32_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_s8 (int8x8_t)
+@item float32x2_t vreinterpret_f32_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_u64 (uint64x1_t)
+@item float32x2_t vreinterpret_f32_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_s64 (int64x1_t)
+@item float32x2_t vreinterpret_f32_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_f32 (float32x2_t)
+@item float32x2_t vreinterpret_f32_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x4_t vreinterpret_p16_p8 (poly8x8_t)
+@item float32x2_t vreinterpret_f32_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_u32 (uint32x4_t)
+@item float32x2_t vreinterpret_f32_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_u16 (uint16x8_t)
+@item float32x2_t vreinterpret_f32_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_u8 (uint8x16_t)
+@item poly64x1_t vreinterpret_p64_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_s32 (int32x4_t)
+@item poly64x1_t vreinterpret_p64_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_s16 (int16x8_t)
+@item poly64x1_t vreinterpret_p64_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_s8 (int8x16_t)
+@item poly64x1_t vreinterpret_p64_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_u64 (uint64x2_t)
+@item poly64x1_t vreinterpret_p64_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_s64 (int64x2_t)
+@item poly64x1_t vreinterpret_p64_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_f32 (float32x4_t)
+@item poly64x1_t vreinterpret_p64_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item poly16x8_t vreinterpretq_p16_p8 (poly8x16_t)
+@item poly64x1_t vreinterpret_p64_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_u32 (uint32x2_t)
+@item poly64x1_t vreinterpret_p64_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_u16 (uint16x4_t)
+@item poly64x1_t vreinterpret_p64_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_u8 (uint8x8_t)
+@item poly64x1_t vreinterpret_p64_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_s32 (int32x2_t)
+@item int64x1_t vreinterpret_s64_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_s16 (int16x4_t)
+@item int64x1_t vreinterpret_s64_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_s8 (int8x8_t)
+@item int64x1_t vreinterpret_s64_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_u64 (uint64x1_t)
+@item int64x1_t vreinterpret_s64_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_s64 (int64x1_t)
+@item int64x1_t vreinterpret_s64_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_p16 (poly16x4_t)
+@item int64x1_t vreinterpret_s64_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x2_t vreinterpret_f32_p8 (poly8x8_t)
+@item int64x1_t vreinterpret_s64_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_u32 (uint32x4_t)
+@item int64x1_t vreinterpret_s64_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_u16 (uint16x8_t)
+@item int64x1_t vreinterpret_s64_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_u8 (uint8x16_t)
+@item int64x1_t vreinterpret_s64_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_s32 (int32x4_t)
+@item int64x1_t vreinterpret_s64_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_s16 (int16x8_t)
+@item uint64x1_t vreinterpret_u64_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_s8 (int8x16_t)
+@item uint64x1_t vreinterpret_u64_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_u64 (uint64x2_t)
+@item uint64x1_t vreinterpret_u64_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_s64 (int64x2_t)
+@item uint64x1_t vreinterpret_u64_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_p16 (poly16x8_t)
+@item uint64x1_t vreinterpret_u64_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item float32x4_t vreinterpretq_f32_p8 (poly8x16_t)
+@item uint64x1_t vreinterpret_u64_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_u32 (uint32x2_t)
+@item uint64x1_t vreinterpret_u64_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_u16 (uint16x4_t)
+@item uint64x1_t vreinterpret_u64_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_u8 (uint8x8_t)
+@item uint64x1_t vreinterpret_u64_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_s32 (int32x2_t)
+@item uint64x1_t vreinterpret_u64_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_s16 (int16x4_t)
+@item uint64x1_t vreinterpret_u64_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_s8 (int8x8_t)
+@item int8x8_t vreinterpret_s8_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_u64 (uint64x1_t)
+@item int8x8_t vreinterpret_s8_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_f32 (float32x2_t)
+@item int8x8_t vreinterpret_s8_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_p16 (poly16x4_t)
+@item int8x8_t vreinterpret_s8_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x1_t vreinterpret_s64_p8 (poly8x8_t)
+@item int8x8_t vreinterpret_s8_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_u32 (uint32x4_t)
+@item int8x8_t vreinterpret_s8_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_u16 (uint16x8_t)
+@item int8x8_t vreinterpret_s8_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_u8 (uint8x16_t)
+@item int8x8_t vreinterpret_s8_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_s32 (int32x4_t)
+@item int8x8_t vreinterpret_s8_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_s16 (int16x8_t)
+@item int8x8_t vreinterpret_s8_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_s8 (int8x16_t)
+@item int8x8_t vreinterpret_s8_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_u64 (uint64x2_t)
+@item int16x4_t vreinterpret_s16_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_f32 (float32x4_t)
+@item int16x4_t vreinterpret_s16_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_p16 (poly16x8_t)
+@item int16x4_t vreinterpret_s16_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int64x2_t vreinterpretq_s64_p8 (poly8x16_t)
+@item int16x4_t vreinterpret_s16_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_u32 (uint32x2_t)
+@item int16x4_t vreinterpret_s16_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_u16 (uint16x4_t)
+@item int16x4_t vreinterpret_s16_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_u8 (uint8x8_t)
+@item int16x4_t vreinterpret_s16_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_s32 (int32x2_t)
+@item int16x4_t vreinterpret_s16_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_s16 (int16x4_t)
+@item int16x4_t vreinterpret_s16_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_s8 (int8x8_t)
+@item int16x4_t vreinterpret_s16_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_s64 (int64x1_t)
+@item int16x4_t vreinterpret_s16_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_f32 (float32x2_t)
+@item int32x2_t vreinterpret_s32_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_p16 (poly16x4_t)
+@item int32x2_t vreinterpret_s32_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x1_t vreinterpret_u64_p8 (poly8x8_t)
+@item int32x2_t vreinterpret_s32_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_u32 (uint32x4_t)
+@item int32x2_t vreinterpret_s32_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_u16 (uint16x8_t)
+@item int32x2_t vreinterpret_s32_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_u8 (uint8x16_t)
+@item int32x2_t vreinterpret_s32_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_s32 (int32x4_t)
+@item int32x2_t vreinterpret_s32_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_s16 (int16x8_t)
+@item int32x2_t vreinterpret_s32_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_s8 (int8x16_t)
+@item int32x2_t vreinterpret_s32_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_s64 (int64x2_t)
+@item int32x2_t vreinterpret_s32_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_f32 (float32x4_t)
+@item int32x2_t vreinterpret_s32_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_p16 (poly16x8_t)
+@item uint8x8_t vreinterpret_u8_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint64x2_t vreinterpretq_u64_p8 (poly8x16_t)
+@item uint8x8_t vreinterpret_u8_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_u32 (uint32x2_t)
+@item uint8x8_t vreinterpret_u8_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_u16 (uint16x4_t)
+@item uint8x8_t vreinterpret_u8_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_u8 (uint8x8_t)
+@item uint8x8_t vreinterpret_u8_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_s32 (int32x2_t)
+@item uint8x8_t vreinterpret_u8_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_s16 (int16x4_t)
+@item uint8x8_t vreinterpret_u8_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_u64 (uint64x1_t)
+@item uint8x8_t vreinterpret_u8_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_s64 (int64x1_t)
+@item uint8x8_t vreinterpret_u8_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_f32 (float32x2_t)
+@item uint8x8_t vreinterpret_u8_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_p16 (poly16x4_t)
+@item uint8x8_t vreinterpret_u8_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x8_t vreinterpret_s8_p8 (poly8x8_t)
+@item uint16x4_t vreinterpret_u16_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_u32 (uint32x4_t)
+@item uint16x4_t vreinterpret_u16_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_u16 (uint16x8_t)
+@item uint16x4_t vreinterpret_u16_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_u8 (uint8x16_t)
+@item uint16x4_t vreinterpret_u16_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_s32 (int32x4_t)
+@item uint16x4_t vreinterpret_u16_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_s16 (int16x8_t)
+@item uint16x4_t vreinterpret_u16_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_u64 (uint64x2_t)
+@item uint16x4_t vreinterpret_u16_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_s64 (int64x2_t)
+@item uint16x4_t vreinterpret_u16_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_f32 (float32x4_t)
+@item uint16x4_t vreinterpret_u16_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_p16 (poly16x8_t)
+@item uint16x4_t vreinterpret_u16_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int8x16_t vreinterpretq_s8_p8 (poly8x16_t)
+@item uint16x4_t vreinterpret_u16_u32 (uint32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_u32 (uint32x2_t)
+@item uint32x2_t vreinterpret_u32_p8 (poly8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_u16 (uint16x4_t)
+@item uint32x2_t vreinterpret_u32_p16 (poly16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_u8 (uint8x8_t)
+@item uint32x2_t vreinterpret_u32_f32 (float32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_s32 (int32x2_t)
+@item uint32x2_t vreinterpret_u32_p64 (poly64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_s8 (int8x8_t)
+@item uint32x2_t vreinterpret_u32_s64 (int64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_u64 (uint64x1_t)
+@item uint32x2_t vreinterpret_u32_u64 (uint64x1_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_s64 (int64x1_t)
+@item uint32x2_t vreinterpret_u32_s8 (int8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_f32 (float32x2_t)
+@item uint32x2_t vreinterpret_u32_s16 (int16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_p16 (poly16x4_t)
+@item uint32x2_t vreinterpret_u32_s32 (int32x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x4_t vreinterpret_s16_p8 (poly8x8_t)
+@item uint32x2_t vreinterpret_u32_u8 (uint8x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_u32 (uint32x4_t)
+@item uint32x2_t vreinterpret_u32_u16 (uint16x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_u16 (uint16x8_t)
+@item poly8x16_t vreinterpretq_p8_p16 (poly16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_u8 (uint8x16_t)
+@item poly8x16_t vreinterpretq_p8_f32 (float32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_s32 (int32x4_t)
+@item poly8x16_t vreinterpretq_p8_p64 (poly64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_s8 (int8x16_t)
+@item poly8x16_t vreinterpretq_p8_p128 (poly128_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_u64 (uint64x2_t)
+@item poly8x16_t vreinterpretq_p8_s64 (int64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_s64 (int64x2_t)
+@item poly8x16_t vreinterpretq_p8_u64 (uint64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_f32 (float32x4_t)
+@item poly8x16_t vreinterpretq_p8_s8 (int8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_p16 (poly16x8_t)
+@item poly8x16_t vreinterpretq_p8_s16 (int16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int16x8_t vreinterpretq_s16_p8 (poly8x16_t)
+@item poly8x16_t vreinterpretq_p8_s32 (int32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_u32 (uint32x2_t)
+@item poly8x16_t vreinterpretq_p8_u8 (uint8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_u16 (uint16x4_t)
+@item poly8x16_t vreinterpretq_p8_u16 (uint16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_u8 (uint8x8_t)
+@item poly8x16_t vreinterpretq_p8_u32 (uint32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_s16 (int16x4_t)
+@item poly16x8_t vreinterpretq_p16_p8 (poly8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_s8 (int8x8_t)
+@item poly16x8_t vreinterpretq_p16_f32 (float32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_u64 (uint64x1_t)
+@item poly16x8_t vreinterpretq_p16_p64 (poly64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_s64 (int64x1_t)
+@item poly16x8_t vreinterpretq_p16_p128 (poly128_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_f32 (float32x2_t)
+@item poly16x8_t vreinterpretq_p16_s64 (int64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_p16 (poly16x4_t)
+@item poly16x8_t vreinterpretq_p16_u64 (uint64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x2_t vreinterpret_s32_p8 (poly8x8_t)
+@item poly16x8_t vreinterpretq_p16_s8 (int8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_u32 (uint32x4_t)
+@item poly16x8_t vreinterpretq_p16_s16 (int16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_u16 (uint16x8_t)
+@item poly16x8_t vreinterpretq_p16_s32 (int32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_u8 (uint8x16_t)
+@item poly16x8_t vreinterpretq_p16_u8 (uint8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_s16 (int16x8_t)
+@item poly16x8_t vreinterpretq_p16_u16 (uint16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_s8 (int8x16_t)
+@item poly16x8_t vreinterpretq_p16_u32 (uint32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_u64 (uint64x2_t)
+@item float32x4_t vreinterpretq_f32_p8 (poly8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_s64 (int64x2_t)
+@item float32x4_t vreinterpretq_f32_p16 (poly16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_f32 (float32x4_t)
+@item float32x4_t vreinterpretq_f32_p64 (poly64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_p16 (poly16x8_t)
+@item float32x4_t vreinterpretq_f32_p128 (poly128_t)
 @end itemize
 
 
 @itemize @bullet
-@item int32x4_t vreinterpretq_s32_p8 (poly8x16_t)
+@item float32x4_t vreinterpretq_f32_s64 (int64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_u32 (uint32x2_t)
+@item float32x4_t vreinterpretq_f32_u64 (uint64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_u16 (uint16x4_t)
+@item float32x4_t vreinterpretq_f32_s8 (int8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_s32 (int32x2_t)
+@item float32x4_t vreinterpretq_f32_s16 (int16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_s16 (int16x4_t)
+@item float32x4_t vreinterpretq_f32_s32 (int32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_s8 (int8x8_t)
+@item float32x4_t vreinterpretq_f32_u8 (uint8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_u64 (uint64x1_t)
+@item float32x4_t vreinterpretq_f32_u16 (uint16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_s64 (int64x1_t)
+@item float32x4_t vreinterpretq_f32_u32 (uint32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_f32 (float32x2_t)
+@item poly64x2_t vreinterpretq_p64_p8 (poly8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_p16 (poly16x4_t)
+@item poly64x2_t vreinterpretq_p64_p16 (poly16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x8_t vreinterpret_u8_p8 (poly8x8_t)
+@item poly64x2_t vreinterpretq_p64_f32 (float32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_u32 (uint32x4_t)
+@item poly64x2_t vreinterpretq_p64_p128 (poly128_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_u16 (uint16x8_t)
+@item poly64x2_t vreinterpretq_p64_s64 (int64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_s32 (int32x4_t)
+@item poly64x2_t vreinterpretq_p64_u64 (uint64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_s16 (int16x8_t)
+@item poly64x2_t vreinterpretq_p64_s8 (int8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_s8 (int8x16_t)
+@item poly64x2_t vreinterpretq_p64_s16 (int16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_u64 (uint64x2_t)
+@item poly64x2_t vreinterpretq_p64_s32 (int32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_s64 (int64x2_t)
+@item poly64x2_t vreinterpretq_p64_u8 (uint8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_f32 (float32x4_t)
+@item poly64x2_t vreinterpretq_p64_u16 (uint16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint8x16_t vreinterpretq_u8_p16 (poly16x8_t)
+@item poly64x2_t vreinterpretq_p64_u32 (uint32x4_t)
 @end itemize
 
 
 @itemize @bullet
+@item poly128_t vreinterpretq_p128_p8 (poly8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_p16 (poly16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_f32 (float32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_s64 (int64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_u64 (uint64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_s8 (int8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_s16 (int16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_s32 (int32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_u8 (uint8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_u16 (uint16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item poly128_t vreinterpretq_p128_u32 (uint32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_p8 (poly8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_p16 (poly16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_f32 (float32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_p128 (poly128_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_u64 (uint64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_s8 (int8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_s16 (int16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_s32 (int32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_u8 (uint8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_u16 (uint16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int64x2_t vreinterpretq_s64_u32 (uint32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_p8 (poly8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_p16 (poly16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_f32 (float32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_p128 (poly128_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_s64 (int64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_s8 (int8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_s16 (int16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_s32 (int32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_u8 (uint8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_u16 (uint16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item uint64x2_t vreinterpretq_u64_u32 (uint32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_p8 (poly8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_p16 (poly16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_f32 (float32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_p128 (poly128_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_s64 (int64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_u64 (uint64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_s16 (int16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_s32 (int32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_u8 (uint8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_u16 (uint16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int8x16_t vreinterpretq_s8_u32 (uint32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_p8 (poly8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_p16 (poly16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_f32 (float32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_p128 (poly128_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_s64 (int64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_u64 (uint64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_s8 (int8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_s32 (int32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_u8 (uint8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_u16 (uint16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int16x8_t vreinterpretq_s16_u32 (uint32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_p8 (poly8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_p16 (poly16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_f32 (float32x4_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_p64 (poly64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_p128 (poly128_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_s64 (int64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_u64 (uint64x2_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_s8 (int8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_s16 (int16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_u8 (uint8x16_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_u16 (uint16x8_t)
+@end itemize
+
+
+@itemize @bullet
+@item int32x4_t vreinterpretq_s32_u32 (uint32x4_t)
+@end itemize
+
+
+@itemize @bullet
 @item uint8x16_t vreinterpretq_u8_p8 (poly8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_u32 (uint32x2_t)
+@item uint8x16_t vreinterpretq_u8_p16 (poly16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_u8 (uint8x8_t)
+@item uint8x16_t vreinterpretq_u8_f32 (float32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_s32 (int32x2_t)
+@item uint8x16_t vreinterpretq_u8_p64 (poly64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_s16 (int16x4_t)
+@item uint8x16_t vreinterpretq_u8_p128 (poly128_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_s8 (int8x8_t)
+@item uint8x16_t vreinterpretq_u8_s64 (int64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_u64 (uint64x1_t)
+@item uint8x16_t vreinterpretq_u8_u64 (uint64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_s64 (int64x1_t)
+@item uint8x16_t vreinterpretq_u8_s8 (int8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_f32 (float32x2_t)
+@item uint8x16_t vreinterpretq_u8_s16 (int16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_p16 (poly16x4_t)
+@item uint8x16_t vreinterpretq_u8_s32 (int32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x4_t vreinterpret_u16_p8 (poly8x8_t)
+@item uint8x16_t vreinterpretq_u8_u16 (uint16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_u32 (uint32x4_t)
+@item uint8x16_t vreinterpretq_u8_u32 (uint32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_u8 (uint8x16_t)
+@item uint16x8_t vreinterpretq_u16_p8 (poly8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_s32 (int32x4_t)
+@item uint16x8_t vreinterpretq_u16_p16 (poly16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_s16 (int16x8_t)
+@item uint16x8_t vreinterpretq_u16_f32 (float32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_s8 (int8x16_t)
+@item uint16x8_t vreinterpretq_u16_p64 (poly64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_u64 (uint64x2_t)
+@item uint16x8_t vreinterpretq_u16_p128 (poly128_t)
 @end itemize
 
 
@@ -11259,77 +11838,77 @@
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_f32 (float32x4_t)
+@item uint16x8_t vreinterpretq_u16_u64 (uint64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_p16 (poly16x8_t)
+@item uint16x8_t vreinterpretq_u16_s8 (int8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint16x8_t vreinterpretq_u16_p8 (poly8x16_t)
+@item uint16x8_t vreinterpretq_u16_s16 (int16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_u16 (uint16x4_t)
+@item uint16x8_t vreinterpretq_u16_s32 (int32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_u8 (uint8x8_t)
+@item uint16x8_t vreinterpretq_u16_u8 (uint8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_s32 (int32x2_t)
+@item uint16x8_t vreinterpretq_u16_u32 (uint32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_s16 (int16x4_t)
+@item uint32x4_t vreinterpretq_u32_p8 (poly8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_s8 (int8x8_t)
+@item uint32x4_t vreinterpretq_u32_p16 (poly16x8_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_u64 (uint64x1_t)
+@item uint32x4_t vreinterpretq_u32_f32 (float32x4_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_s64 (int64x1_t)
+@item uint32x4_t vreinterpretq_u32_p64 (poly64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_f32 (float32x2_t)
+@item uint32x4_t vreinterpretq_u32_p128 (poly128_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_p16 (poly16x4_t)
+@item uint32x4_t vreinterpretq_u32_s64 (int64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x2_t vreinterpret_u32_p8 (poly8x8_t)
+@item uint32x4_t vreinterpretq_u32_u64 (uint64x2_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_u16 (uint16x8_t)
+@item uint32x4_t vreinterpretq_u32_s8 (int8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_u8 (uint8x16_t)
+@item uint32x4_t vreinterpretq_u32_s16 (int16x8_t)
 @end itemize
 
 
@@ -11339,39 +11918,91 @@
 
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_s16 (int16x8_t)
+@item uint32x4_t vreinterpretq_u32_u8 (uint8x16_t)
 @end itemize
 
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_s8 (int8x16_t)
+@item uint32x4_t vreinterpretq_u32_u16 (uint16x8_t)
 @end itemize
 
 
+
+
+
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_u64 (uint64x2_t)
+@item poly128_t vldrq_p128(poly128_t const *)
 @end itemize
 
+@itemize @bullet
+@item void vstrq_p128(poly128_t *, poly128_t)
+@end itemize
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_s64 (int64x2_t)
+@item uint64x1_t vceq_p64 (poly64x1_t, poly64x1_t)
 @end itemize
 
+@itemize @bullet
+@item uint64x1_t vtst_p64 (poly64x1_t, poly64x1_t)
+@end itemize
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_f32 (float32x4_t)
+@item uint32_t vsha1h_u32 (uint32_t)
+@*@emph{Form of expected instruction(s):} @code{sha1h.32 @var{q0}, @var{q1}}
 @end itemize
 
+@itemize @bullet
+@item uint32x4_t vsha1cq_u32 (uint32x4_t, uint32_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha1c.32 @var{q0}, @var{q1}, @var{q2}}
+@end itemize
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_p16 (poly16x8_t)
+@item uint32x4_t vsha1pq_u32 (uint32x4_t, uint32_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha1p.32 @var{q0}, @var{q1}, @var{q2}}
 @end itemize
 
+@itemize @bullet
+@item uint32x4_t vsha1mq_u32 (uint32x4_t, uint32_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha1m.32 @var{q0}, @var{q1}, @var{q2}}
+@end itemize
 
 @itemize @bullet
-@item uint32x4_t vreinterpretq_u32_p8 (poly8x16_t)
+@item uint32x4_t vsha1su0q_u32 (uint32x4_t, uint32x4_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha1su0.32 @var{q0}, @var{q1}, @var{q2}}
 @end itemize
 
+@itemize @bullet
+@item uint32x4_t vsha1su1q_u32 (uint32x4_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha1su1.32 @var{q0}, @var{q1}, @var{q2}}
+@end itemize
 
+@itemize @bullet
+@item uint32x4_t vsha256hq_u32 (uint32x4_t, uint32x4_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha256h.32 @var{q0}, @var{q1}, @var{q2}}
+@end itemize
+ 
+@itemize @bullet
+@item uint32x4_t vsha256h2q_u32 (uint32x4_t, uint32x4_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha256h2.32 @var{q0}, @var{q1}, @var{q2}}
+@end itemize
+ 
+@itemize @bullet
+@item uint32x4_t vsha256su0q_u32 (uint32x4_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha256su0.32 @var{q0}, @var{q1}}
+@end itemize
+ 
+@itemize @bullet
+@item uint32x4_t vsha256su1q_u32 (uint32x4_t, uint32x4_t, uint32x4_t)
+@*@emph{Form of expected instruction(s):} @code{sha256su1.32 @var{q0}, @var{q1}, @var{q2}}
+@end itemize
 
+@itemize @bullet
+@item poly128_t vmull_p64 (poly64_t a, poly64_t b)
+@*@emph{Form of expected instruction(s):} @code{vmull.p64 @var{q0}, @var{d1}, @var{d2}}
+@end itemize
 
+@itemize @bullet
+@item poly128_t vmull_high_p64 (poly64x2_t a, poly64x2_t b)
+@*@emph{Form of expected instruction(s):} @code{vmull.p64 @var{q0}, @var{d1}, @var{d2}}
+@end itemize
+
--- a/src/gcc/doc/md.texi
+++ b/src/gcc/doc/md.texi
@@ -1711,9 +1711,6 @@
 @item Z
 Integer constant zero
 
-@item Usa
-An absolute symbolic address
-
 @item Ush
 The high part (bits 12 and upwards) of the pc-relative address of a symbol
 within 4GB of the instruction
@@ -8880,7 +8877,8 @@
 (define_cond_exec
   [@var{predicate-pattern}]
   "@var{condition}"
-  "@var{output-template}")
+  "@var{output-template}"
+  "@var{optional-insn-attribues}")
 @end smallexample
 
 @var{predicate-pattern} is the condition that must be true for the
@@ -8901,6 +8899,13 @@
 @code{current_insn_predicate} that will contain the entire predicate
 if the current insn is predicated, and will otherwise be @code{NULL}.
 
+@var{optional-insn-attributes} is an optional vector of attributes that gets
+appended to the insn attributes of the produced cond_exec rtx. It can
+be used to add some distinguishing attribute to cond_exec rtxs produced
+that way. An example usage would be to use this attribute in conjunction
+with attributes on the main pattern to disable particular alternatives under
+certain conditions.
+
 When @code{define_cond_exec} is used, an implicit reference to
 the @code{predicable} instruction attribute is made.
 @xref{Insn Attributes}.  This attribute must be a boolean (i.e.@: have
@@ -9657,7 +9662,7 @@
 		      QABSNEG))]
   "TARGET_NEON"
   "vq<absneg>.<V_s_elem>\t%<V_reg>0, %<V_reg>1"
-  [(set_attr "neon_type" "neon_vqneg_vqabs")]
+  [(set_attr "type" "neon_vqneg_vqabs")]
 )
 
 @end smallexample
@@ -9672,7 +9677,7 @@
 		      UNSPEC_VQABS))]
   "TARGET_NEON"
   "vqabs.<V_s_elem>\t%<V_reg>0, %<V_reg>1"
-  [(set_attr "neon_type" "neon_vqneg_vqabs")]
+  [(set_attr "type" "neon_vqneg_vqabs")]
 )
 
 (define_insn "neon_vqneg<mode>"
@@ -9682,7 +9687,7 @@
 		      UNSPEC_VQNEG))]
   "TARGET_NEON"
   "vqneg.<V_s_elem>\t%<V_reg>0, %<V_reg>1"
-  [(set_attr "neon_type" "neon_vqneg_vqabs")]
+  [(set_attr "type" "neon_vqneg_vqabs")]
 )
 
 @end smallexample

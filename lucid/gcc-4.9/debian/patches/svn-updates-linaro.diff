# DP: Revert 2014-09-11 Aarch64 neon changes, not merged with Linaro.

Index: b/src/gcc/ChangeLog
===================================================================
--- a/src/gcc/ChangeLog
+++ b/src/gcc/ChangeLog
@@ -16,54 +16,6 @@
 	* config/i386/i386.c (ix86_option_override_internal): Also turn
 	off OPTION_MASK_ABI_X32 for -m16.
 
-2014-09-11  James Greenhalgh  <james.greenhalgh@arm.com>
-
-	Backport from mainline.
-	2014-09-11  James Greenhalgh  <james.greenhalgh@arm.com>
-
-	* config/aarch64/arm_neon.h (vmull_high_lane_s16): Fix argument
-	types.
-	(vmull_high_lane_s32): Likewise.
-	(vmull_high_lane_u16): Likewise.
-	(vmull_high_lane_u32): Likewise.
-
-2014-09-11  Alan Lawrence  <alan.lawrence@arm.com>
-
-	Backport r214946 from mainline
-	2014-09-05  Alan Lawrence  <alan.lawrence@arm.com>
-
-	* config/aarch64/aarch64.md (adddi3_aarch64): Set type to neon_add.
-
-2014-09-11  Alan Lawrence  <alan.lawrence@arm.com>
-
-	Backport r214953 from mainline
-	2014-09-05  Alan Lawrence  <alan.lawrence@arm.com>
-
-	* config/aarch64/arm_neon.h (int32x1_t, int16x1_t, int8x1_t,
-	uint32x1_t, uint16x1_t, uint8x1_t): Remove typedefs.
-
-	(vqabsb_s8, vqabsh_s16, vqabss_s32, vqaddb_s8, vqaddh_s16, vqadds_s32,
-	vqaddb_u8, vqaddh_u16, vqadds_u32, vqdmlalh_s16, vqdmlalh_lane_s16,
-	vqdmlals_s32, vqdmlslh_s16, vqdmlslh_lane_s16, vqdmlsls_s32,
-	vqdmulhh_s16, vqdmulhh_lane_s16, vqdmulhs_s32, vqdmulhs_lane_s32,
-	vqdmullh_s16, vqdmullh_lane_s16, vqdmulls_s32, vqdmulls_lane_s32,
-	vqmovnh_s16, vqmovns_s32, vqmovnd_s64, vqmovnh_u16, vqmovns_u32,
-	vqmovnd_u64, vqmovunh_s16, vqmovuns_s32, vqmovund_s64, vqnegb_s8,
-	vqnegh_s16, vqnegs_s32, vqrdmulhh_s16, vqrdmulhh_lane_s16,
-	vqrdmulhs_s32, vqrdmulhs_lane_s32, vqrshlb_s8, vqrshlh_s16,
-	vqrshls_s32, vqrshlb_u8, vqrshlh_u16, vqrshls_u32, vqrshrnh_n_s16,
-	vqrshrns_n_s32, vqrshrnd_n_s64, vqrshrnh_n_u16, vqrshrns_n_u32,
-	vqrshrnd_n_u64, vqrshrunh_n_s16, vqrshruns_n_s32, vqrshrund_n_s64,
-	vqshlb_s8, vqshlh_s16, vqshls_s32, vqshlb_u8, vqshlh_u16, vqshls_u32,
-	vqshlb_n_s8, vqshlh_n_s16, vqshls_n_s32, vqshlb_n_u8, vqshlh_n_u16,
-	vqshls_n_u32, vqshlub_n_s8, vqshluh_n_s16, vqshlus_n_s32,
-	vqshrnh_n_s16, vqshrns_n_s32, vqshrnd_n_s64, vqshrnh_n_u16,
-	vqshrns_n_u32, vqshrnd_n_u64, vqshrunh_n_s16, vqshruns_n_s32,
-	vqshrund_n_s64, vqsubb_s8, vqsubh_s16, vqsubs_s32, vqsubb_u8,
-	vqsubh_u16, vqsubs_u32, vsqaddb_u8, vsqaddh_u16, vsqadds_u32,
-	vuqaddb_s8, vuqaddh_s16, vuqadds_s32): Replace all int{32,16,8}x1_t
-	with int{32,16,8}_t.
-
 2014-09-11  Jason Merrill  <jason@redhat.com>
 
 	PR c++/58678
Index: b/src/gcc/testsuite/gcc.target/aarch64/vqdmullh_lane_s16.c
===================================================================
--- a/src/gcc/testsuite/gcc.target/aarch64/vqdmullh_lane_s16.c
+++ b/src/gcc/testsuite/gcc.target/aarch64/vqdmullh_lane_s16.c
@@ -5,8 +5,8 @@
 
 #include "arm_neon.h"
 
-int32_t
-t_vqdmullh_lane_s16 (int16_t a, int16x4_t b)
+int32x1_t
+t_vqdmullh_lane_s16 (int16x1_t a, int16x4_t b)
 {
   return vqdmullh_lane_s16 (a, b, 0);
 }
Index: b/src/gcc/testsuite/gcc.target/aarch64/vqdmlalh_lane_s16.c
===================================================================
--- a/src/gcc/testsuite/gcc.target/aarch64/vqdmlalh_lane_s16.c
+++ b/src/gcc/testsuite/gcc.target/aarch64/vqdmlalh_lane_s16.c
@@ -5,8 +5,8 @@
 
 #include "arm_neon.h"
 
-int32_t
-t_vqdmlalh_lane_s16 (int32_t a, int16_t b, int16x4_t c)
+int32x1_t
+t_vqdmlalh_lane_s16 (int32x1_t a, int16x1_t b, int16x4_t c)
 {
   return vqdmlalh_lane_s16 (a, b, c, 0);
 }
Index: b/src/gcc/testsuite/gcc.target/aarch64/vqdmlsls_lane_s32.c
===================================================================
--- a/src/gcc/testsuite/gcc.target/aarch64/vqdmlsls_lane_s32.c
+++ b/src/gcc/testsuite/gcc.target/aarch64/vqdmlsls_lane_s32.c
@@ -6,7 +6,7 @@
 #include "arm_neon.h"
 
 int64x1_t
-t_vqdmlsls_lane_s32 (int64x1_t a, int32_t b, int32x2_t c)
+t_vqdmlsls_lane_s32 (int64x1_t a, int32x1_t b, int32x2_t c)
 {
   return vqdmlsls_lane_s32 (a, b, c, 0);
 }
Index: b/src/gcc/testsuite/gcc.target/aarch64/vqdmulls_lane_s32.c
===================================================================
--- a/src/gcc/testsuite/gcc.target/aarch64/vqdmulls_lane_s32.c
+++ b/src/gcc/testsuite/gcc.target/aarch64/vqdmulls_lane_s32.c
@@ -6,7 +6,7 @@
 #include "arm_neon.h"
 
 int64x1_t
-t_vqdmulls_lane_s32 (int32_t a, int32x2_t b)
+t_vqdmulls_lane_s32 (int32x1_t a, int32x2_t b)
 {
   return vqdmulls_lane_s32 (a, b, 0);
 }
Index: b/src/gcc/testsuite/gcc.target/aarch64/vqdmlals_lane_s32.c
===================================================================
--- a/src/gcc/testsuite/gcc.target/aarch64/vqdmlals_lane_s32.c
+++ b/src/gcc/testsuite/gcc.target/aarch64/vqdmlals_lane_s32.c
@@ -6,7 +6,7 @@
 #include "arm_neon.h"
 
 int64x1_t
-t_vqdmlals_lane_s32 (int64x1_t a, int32_t b, int32x2_t c)
+t_vqdmlals_lane_s32 (int64x1_t a, int32x1_t b, int32x2_t c)
 {
   return vqdmlals_lane_s32 (a, b, c, 0);
 }
Index: b/src/gcc/testsuite/gcc.target/aarch64/scalar_intrinsics.c
===================================================================
--- a/src/gcc/testsuite/gcc.target/aarch64/scalar_intrinsics.c
+++ b/src/gcc/testsuite/gcc.target/aarch64/scalar_intrinsics.c
@@ -195,20 +195,20 @@ test_vcltzd_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "aarch64_get_lanev16qi" 2 } } */
 
-int8_t
+int8x1_t
 test_vdupb_lane_s8 (int8x16_t a)
 {
-  int8_t res;
+  int8x1_t res;
   force_simd (a);
   res = vdupb_laneq_s8 (a, 2);
   force_simd (res);
   return res;
 }
 
-uint8_t
+uint8x1_t
 test_vdupb_lane_u8 (uint8x16_t a)
 {
-  uint8_t res;
+  uint8x1_t res;
   force_simd (a);
   res = vdupb_laneq_u8 (a, 2);
   force_simd (res);
@@ -217,20 +217,20 @@ test_vdupb_lane_u8 (uint8x16_t a)
 
 /* { dg-final { scan-assembler-times "aarch64_get_lanev8hi" 2 } } */
 
-int16_t
+int16x1_t
 test_vduph_lane_s16 (int16x8_t a)
 {
-  int16_t res;
+  int16x1_t res;
   force_simd (a);
   res = vduph_laneq_s16 (a, 2);
   force_simd (res);
   return res;
 }
 
-uint16_t
+uint16x1_t
 test_vduph_lane_u16 (uint16x8_t a)
 {
-  uint16_t res;
+  uint16x1_t res;
   force_simd (a);
   res = vduph_laneq_u16 (a, 2);
   force_simd (res);
@@ -239,20 +239,20 @@ test_vduph_lane_u16 (uint16x8_t a)
 
 /* { dg-final { scan-assembler-times "aarch64_get_lanev4si" 2 } } */
 
-int32_t
+int32x1_t
 test_vdups_lane_s32 (int32x4_t a)
 {
-  int32_t res;
+  int32x1_t res;
   force_simd (a);
   res = vdups_laneq_s32 (a, 2);
   force_simd (res);
   return res;
 }
 
-uint32_t
+uint32x1_t
 test_vdups_lane_u32 (uint32x4_t a)
 {
-  uint32_t res;
+  uint32x1_t res;
   force_simd (a);
   res = vdups_laneq_u32 (a, 2);
   force_simd (res);
@@ -322,24 +322,24 @@ test_vqaddd_u64 (uint64x1_t a, uint64x1_
 
 /* { dg-final { scan-assembler-times "\\tuqadd\\ts\[0-9\]+" 1 } } */
 
-uint32_t
-test_vqadds_u32 (uint32_t a, uint32_t b)
+uint32x1_t
+test_vqadds_u32 (uint32x1_t a, uint32x1_t b)
 {
   return vqadds_u32 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqadd\\th\[0-9\]+" 1 } } */
 
-uint16_t
-test_vqaddh_u16 (uint16_t a, uint16_t b)
+uint16x1_t
+test_vqaddh_u16 (uint16x1_t a, uint16x1_t b)
 {
   return vqaddh_u16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqadd\\tb\[0-9\]+" 1 } } */
 
-uint8_t
-test_vqaddb_u8 (uint8_t a, uint8_t b)
+uint8x1_t
+test_vqaddb_u8 (uint8x1_t a, uint8x1_t b)
 {
   return vqaddb_u8 (a, b);
 }
@@ -354,40 +354,40 @@ test_vqaddd_s64 (int64x1_t a, int64x1_t
 
 /* { dg-final { scan-assembler-times "\\tsqadd\\ts\[0-9\]+, s\[0-9\]+" 1 } } */
 
-int32_t
-test_vqadds_s32 (int32_t a, int32_t b)
+int32x1_t
+test_vqadds_s32 (int32x1_t a, int32x1_t b)
 {
   return vqadds_s32 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqadd\\th\[0-9\]+, h\[0-9\]+" 1 } } */
 
-int16_t
-test_vqaddh_s16 (int16_t a, int16_t b)
+int16x1_t
+test_vqaddh_s16 (int16x1_t a, int16x1_t b)
 {
   return vqaddh_s16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqadd\\tb\[0-9\]+, b\[0-9\]+" 1 } } */
 
-int8_t
-test_vqaddb_s8 (int8_t a, int8_t b)
+int8x1_t
+test_vqaddb_s8 (int8x1_t a, int8x1_t b)
 {
   return vqaddb_s8 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmlal\\ts\[0-9\]+, h\[0-9\]+, h\[0-9\]+" 1 } } */
 
-int32_t
-test_vqdmlalh_s16 (int32_t a, int16_t b, int16_t c)
+int32x1_t
+test_vqdmlalh_s16 (int32x1_t a, int16x1_t b, int16x1_t c)
 {
   return vqdmlalh_s16 (a, b, c);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmlal\\ts\[0-9\]+, h\[0-9\]+, v" 1 } } */
 
-int32_t
-test_vqdmlalh_lane_s16 (int32_t a, int16_t b, int16x4_t c)
+int32x1_t
+test_vqdmlalh_lane_s16 (int32x1_t a, int16x1_t b, int16x4_t c)
 {
   return vqdmlalh_lane_s16 (a, b, c, 3);
 }
@@ -395,7 +395,7 @@ test_vqdmlalh_lane_s16 (int32_t a, int16
 /* { dg-final { scan-assembler-times "\\tsqdmlal\\td\[0-9\]+, s\[0-9\]+, s\[0-9\]+" 1 } } */
 
 int64x1_t
-test_vqdmlals_s32 (int64x1_t a, int32_t b, int32_t c)
+test_vqdmlals_s32 (int64x1_t a, int32x1_t b, int32x1_t c)
 {
   return vqdmlals_s32 (a, b, c);
 }
@@ -403,23 +403,23 @@ test_vqdmlals_s32 (int64x1_t a, int32_t
 /* { dg-final { scan-assembler-times "\\tsqdmlal\\td\[0-9\]+, s\[0-9\]+, v" 1 } } */
 
 int64x1_t
-test_vqdmlals_lane_s32 (int64x1_t a, int32_t b, int32x2_t c)
+test_vqdmlals_lane_s32 (int64x1_t a, int32x1_t b, int32x2_t c)
 {
   return vqdmlals_lane_s32 (a, b, c, 1);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmlsl\\ts\[0-9\]+, h\[0-9\]+, h\[0-9\]+" 1 } } */
 
-int32_t
-test_vqdmlslh_s16 (int32_t a, int16_t b, int16_t c)
+int32x1_t
+test_vqdmlslh_s16 (int32x1_t a, int16x1_t b, int16x1_t c)
 {
   return vqdmlslh_s16 (a, b, c);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmlsl\\ts\[0-9\]+, h\[0-9\]+, v" 1 } } */
 
-int32_t
-test_vqdmlslh_lane_s16 (int32_t a, int16_t b, int16x4_t c)
+int32x1_t
+test_vqdmlslh_lane_s16 (int32x1_t a, int16x1_t b, int16x4_t c)
 {
   return vqdmlslh_lane_s16 (a, b, c, 3);
 }
@@ -427,7 +427,7 @@ test_vqdmlslh_lane_s16 (int32_t a, int16
 /* { dg-final { scan-assembler-times "\\tsqdmlsl\\td\[0-9\]+, s\[0-9\]+, s\[0-9\]+" 1 } } */
 
 int64x1_t
-test_vqdmlsls_s32 (int64x1_t a, int32_t b, int32_t c)
+test_vqdmlsls_s32 (int64x1_t a, int32x1_t b, int32x1_t c)
 {
   return vqdmlsls_s32 (a, b, c);
 }
@@ -435,55 +435,55 @@ test_vqdmlsls_s32 (int64x1_t a, int32_t
 /* { dg-final { scan-assembler-times "\\tsqdmlsl\\td\[0-9\]+, s\[0-9\]+, v" 1 } } */
 
 int64x1_t
-test_vqdmlsls_lane_s32 (int64x1_t a, int32_t b, int32x2_t c)
+test_vqdmlsls_lane_s32 (int64x1_t a, int32x1_t b, int32x2_t c)
 {
   return vqdmlsls_lane_s32 (a, b, c, 1);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmulh\\th\[0-9\]+, h\[0-9\]+, h\[0-9\]+" 1 } } */
 
-int16_t
-test_vqdmulhh_s16 (int16_t a, int16_t b)
+int16x1_t
+test_vqdmulhh_s16 (int16x1_t a, int16x1_t b)
 {
   return vqdmulhh_s16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmulh\\th\[0-9\]+, h\[0-9\]+, v" 1 } } */
 
-int16_t
-test_vqdmulhh_lane_s16 (int16_t a, int16x4_t b)
+int16x1_t
+test_vqdmulhh_lane_s16 (int16x1_t a, int16x4_t b)
 {
   return vqdmulhh_lane_s16 (a, b, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmulh\\ts\[0-9\]+, s\[0-9\]+, s\[0-9\]+" 1 } } */
 
-int32_t
-test_vqdmulhs_s32 (int32_t a, int32_t b)
+int32x1_t
+test_vqdmulhs_s32 (int32x1_t a, int32x1_t b)
 {
   return vqdmulhs_s32 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmulh\\ts\[0-9\]+, s\[0-9\]+, v" 1 } } */
 
-int32_t
-test_vqdmulhs_lane_s32 (int32_t a, int32x2_t b)
+int32x1_t
+test_vqdmulhs_lane_s32 (int32x1_t a, int32x2_t b)
 {
   return vqdmulhs_lane_s32 (a, b, 1);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmull\\ts\[0-9\]+, h\[0-9\]+, h\[0-9\]+" 1 } } */
 
-int32_t
-test_vqdmullh_s16 (int16_t a, int16_t b)
+int32x1_t
+test_vqdmullh_s16 (int16x1_t a, int16x1_t b)
 {
   return vqdmullh_s16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqdmull\\ts\[0-9\]+, h\[0-9\]+, v" 1 } } */
 
-int32_t
-test_vqdmullh_lane_s16 (int16_t a, int16x4_t b)
+int32x1_t
+test_vqdmullh_lane_s16 (int16x1_t a, int16x4_t b)
 {
   return vqdmullh_lane_s16 (a, b, 3);
 }
@@ -491,7 +491,7 @@ test_vqdmullh_lane_s16 (int16_t a, int16
 /* { dg-final { scan-assembler-times "\\tsqdmull\\td\[0-9\]+, s\[0-9\]+, s\[0-9\]+" 1 } } */
 
 int64x1_t
-test_vqdmulls_s32 (int32_t a, int32_t b)
+test_vqdmulls_s32 (int32x1_t a, int32x1_t b)
 {
   return vqdmulls_s32 (a, b);
 }
@@ -499,63 +499,63 @@ test_vqdmulls_s32 (int32_t a, int32_t b)
 /* { dg-final { scan-assembler-times "\\tsqdmull\\td\[0-9\]+, s\[0-9\]+, v" 1 } } */
 
 int64x1_t
-test_vqdmulls_lane_s32 (int32_t a, int32x2_t b)
+test_vqdmulls_lane_s32 (int32x1_t a, int32x2_t b)
 {
   return vqdmulls_lane_s32 (a, b, 1);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrdmulh\\th\[0-9\]+, h\[0-9\]+, h\[0-9\]+" 1 } } */
 
-int16_t
-test_vqrdmulhh_s16 (int16_t a, int16_t b)
+int16x1_t
+test_vqrdmulhh_s16 (int16x1_t a, int16x1_t b)
 {
   return vqrdmulhh_s16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrdmulh\\th\[0-9\]+, h\[0-9\]+, v" 1 } } */
 
-int16_t
-test_vqrdmulhh_lane_s16 (int16_t a, int16x4_t b)
+int16x1_t
+test_vqrdmulhh_lane_s16 (int16x1_t a, int16x4_t b)
 {
   return vqrdmulhh_lane_s16 (a, b, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrdmulh\\ts\[0-9\]+, s\[0-9\]+, s\[0-9\]+" 1 } } */
 
-int32_t
-test_vqrdmulhs_s32 (int32_t a, int32_t b)
+int32x1_t
+test_vqrdmulhs_s32 (int32x1_t a, int32x1_t b)
 {
   return vqrdmulhs_s32 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrdmulh\\ts\[0-9\]+, s\[0-9\]+, v" 1 } } */
 
-int32_t
-test_vqrdmulhs_lane_s32 (int32_t a, int32x2_t b)
+int32x1_t
+test_vqrdmulhs_lane_s32 (int32x1_t a, int32x2_t b)
 {
   return vqrdmulhs_lane_s32 (a, b, 1);
 }
 
 /* { dg-final { scan-assembler-times "\\tsuqadd\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vuqaddb_s8 (int8_t a, int8_t b)
+int8x1_t
+test_vuqaddb_s8 (int8x1_t a, int8x1_t b)
 {
   return vuqaddb_s8 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsuqadd\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vuqaddh_s16 (int16_t a, int8_t b)
+int16x1_t
+test_vuqaddh_s16 (int16x1_t a, int8x1_t b)
 {
   return vuqaddh_s16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsuqadd\\ts\[0-9\]+" 1 } } */
 
-int32_t
-test_vuqadds_s32 (int32_t a, int8_t b)
+int32x1_t
+test_vuqadds_s32 (int32x1_t a, int8x1_t b)
 {
   return vuqadds_s32 (a, b);
 }
@@ -563,31 +563,31 @@ test_vuqadds_s32 (int32_t a, int8_t b)
 /* { dg-final { scan-assembler-times "\\tsuqadd\\td\[0-9\]+" 1 } } */
 
 int64x1_t
-test_vuqaddd_s64 (int64x1_t a, int8_t b)
+test_vuqaddd_s64 (int64x1_t a, int8x1_t b)
 {
   return vuqaddd_s64 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tusqadd\\tb\[0-9\]+" 1 } } */
 
-uint8_t
-test_vsqaddb_u8 (uint8_t a, int8_t b)
+uint8x1_t
+test_vsqaddb_u8 (uint8x1_t a, int8x1_t b)
 {
   return vsqaddb_u8 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tusqadd\\th\[0-9\]+" 1 } } */
 
-uint16_t
-test_vsqaddh_u16 (uint16_t a, int8_t b)
+uint16x1_t
+test_vsqaddh_u16 (uint16x1_t a, int8x1_t b)
 {
   return vsqaddh_u16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tusqadd\\ts\[0-9\]+" 1 } } */
 
-uint32_t
-test_vsqadds_u32 (uint32_t a, int8_t b)
+uint32x1_t
+test_vsqadds_u32 (uint32x1_t a, int8x1_t b)
 {
   return vsqadds_u32 (a, b);
 }
@@ -595,78 +595,78 @@ test_vsqadds_u32 (uint32_t a, int8_t b)
 /* { dg-final { scan-assembler-times "\\tusqadd\\td\[0-9\]+" 1 } } */
 
 uint64x1_t
-test_vsqaddd_u64 (uint64x1_t a, int8_t b)
+test_vsqaddd_u64 (uint64x1_t a, int8x1_t b)
 {
   return vsqaddd_u64 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqabs\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqabsb_s8 (int8_t a)
+int8x1_t
+test_vqabsb_s8 (int8x1_t a)
 {
   return vqabsb_s8 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqabs\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqabsh_s16 (int16_t a)
+int16x1_t
+test_vqabsh_s16 (int16x1_t a)
 {
   return vqabsh_s16 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqabs\\ts\[0-9\]+" 1 } } */
 
-int32_t
-test_vqabss_s32 (int32_t a)
+int32x1_t
+test_vqabss_s32 (int32x1_t a)
 {
   return vqabss_s32 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqneg\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqnegb_s8 (int8_t a)
+int8x1_t
+test_vqnegb_s8 (int8x1_t a)
 {
   return vqnegb_s8 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqneg\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqnegh_s16 (int16_t a)
+int16x1_t
+test_vqnegh_s16 (int16x1_t a)
 {
   return vqnegh_s16 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqneg\\ts\[0-9\]+" 1 } } */
 
-int32_t
-test_vqnegs_s32 (int32_t a)
+int32x1_t
+test_vqnegs_s32 (int32x1_t a)
 {
   return vqnegs_s32 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqxtun\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqmovunh_s16 (int16_t a)
+int8x1_t
+test_vqmovunh_s16 (int16x1_t a)
 {
   return vqmovunh_s16 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqxtun\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqmovuns_s32 (int32_t a)
+int16x1_t
+test_vqmovuns_s32 (int32x1_t a)
 {
   return vqmovuns_s32 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqxtun\\ts\[0-9\]+" 1 } } */
 
-int32_t
+int32x1_t
 test_vqmovund_s64 (int64x1_t a)
 {
   return vqmovund_s64 (a);
@@ -674,23 +674,23 @@ test_vqmovund_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tsqxtn\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqmovnh_s16 (int16_t a)
+int8x1_t
+test_vqmovnh_s16 (int16x1_t a)
 {
   return vqmovnh_s16 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqxtn\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqmovns_s32 (int32_t a)
+int16x1_t
+test_vqmovns_s32 (int32x1_t a)
 {
   return vqmovns_s32 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqxtn\\ts\[0-9\]+" 1 } } */
 
-int32_t
+int32x1_t
 test_vqmovnd_s64 (int64x1_t a)
 {
   return vqmovnd_s64 (a);
@@ -698,23 +698,23 @@ test_vqmovnd_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tuqxtn\\tb\[0-9\]+" 1 } } */
 
-uint8_t
-test_vqmovnh_u16 (uint16_t a)
+uint8x1_t
+test_vqmovnh_u16 (uint16x1_t a)
 {
   return vqmovnh_u16 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqxtn\\th\[0-9\]+" 1 } } */
 
-uint16_t
-test_vqmovns_u32 (uint32_t a)
+uint16x1_t
+test_vqmovns_u32 (uint32x1_t a)
 {
   return vqmovns_u32 (a);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqxtn\\ts\[0-9\]+" 1 } } */
 
-uint32_t
+uint32x1_t
 test_vqmovnd_u64 (uint64x1_t a)
 {
   return vqmovnd_u64 (a);
@@ -753,24 +753,24 @@ test_vqsubd_u64 (uint64x1_t a, uint64x1_
 
 /* { dg-final { scan-assembler-times "\\tuqsub\\ts\[0-9\]+" 1 } } */
 
-uint32_t
-test_vqsubs_u32 (uint32_t a, uint32_t b)
+uint32x1_t
+test_vqsubs_u32 (uint32x1_t a, uint32x1_t b)
 {
   return vqsubs_u32 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqsub\\th\[0-9\]+" 1 } } */
 
-uint16_t
-test_vqsubh_u16 (uint16_t a, uint16_t b)
+uint16x1_t
+test_vqsubh_u16 (uint16x1_t a, uint16x1_t b)
 {
   return vqsubh_u16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqsub\\tb\[0-9\]+" 1 } } */
 
-uint8_t
-test_vqsubb_u8 (uint8_t a, uint8_t b)
+uint8x1_t
+test_vqsubb_u8 (uint8x1_t a, uint8x1_t b)
 {
   return vqsubb_u8 (a, b);
 }
@@ -785,24 +785,24 @@ test_vqsubd_s64 (int64x1_t a, int64x1_t
 
 /* { dg-final { scan-assembler-times "\\tsqsub\\ts\[0-9\]+" 1 } } */
 
-int32_t
-test_vqsubs_s32 (int32_t a, int32_t b)
+int32x1_t
+test_vqsubs_s32 (int32x1_t a, int32x1_t b)
 {
   return vqsubs_s32 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqsub\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqsubh_s16 (int16_t a, int16_t b)
+int16x1_t
+test_vqsubh_s16 (int16x1_t a, int16x1_t b)
 {
   return vqsubh_s16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqsub\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqsubb_s8 (int8_t a, int8_t b)
+int8x1_t
+test_vqsubb_s8 (int8x1_t a, int8x1_t b)
 {
   return vqsubb_s8 (a, b);
 }
@@ -908,24 +908,24 @@ test_vrsrad_n_u64 (uint64x1_t a, uint64x
 
 /* { dg-final { scan-assembler-times "\\tsqrshl\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqrshlb_s8 (int8_t a, int8_t b)
+int8x1_t
+test_vqrshlb_s8 (int8x1_t a, int8x1_t b)
 {
   return vqrshlb_s8 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrshl\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqrshlh_s16 (int16_t a, int16_t b)
+int16x1_t
+test_vqrshlh_s16 (int16x1_t a, int16x1_t b)
 {
   return vqrshlh_s16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrshl\\ts\[0-9\]+" 1 } } */
 
-int32_t
-test_vqrshls_s32 (int32_t a, int32_t b)
+int32x1_t
+test_vqrshls_s32 (int32x1_t a, int32x1_t b)
 {
   return vqrshls_s32 (a, b);
 }
@@ -940,24 +940,24 @@ test_vqrshld_s64 (int64x1_t a, int64x1_t
 
 /* { dg-final { scan-assembler-times "\\tuqrshl\\tb\[0-9\]+" 1 } } */
 
-uint8_t
-test_vqrshlb_u8 (uint8_t a, uint8_t b)
+uint8x1_t
+test_vqrshlb_u8 (uint8x1_t a, uint8x1_t b)
 {
   return vqrshlb_u8 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqrshl\\th\[0-9\]+" 1 } } */
 
-uint16_t
-test_vqrshlh_u16 (uint16_t a, uint16_t b)
+uint16x1_t
+test_vqrshlh_u16 (uint16x1_t a, uint16x1_t b)
 {
   return vqrshlh_u16 (a, b);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqrshl\\ts\[0-9\]+" 1 } } */
 
-uint32_t
-test_vqrshls_u32 (uint32_t a, uint32_t b)
+uint32x1_t
+test_vqrshls_u32 (uint32x1_t a, uint32x1_t b)
 {
   return vqrshls_u32 (a, b);
 }
@@ -972,24 +972,24 @@ test_vqrshld_u64 (uint64x1_t a, uint64x1
 
 /* { dg-final { scan-assembler-times "\\tsqshlu\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqshlub_n_s8 (int8_t a)
+int8x1_t
+test_vqshlub_n_s8 (int8x1_t a)
 {
   return vqshlub_n_s8 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshlu\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqshluh_n_s16 (int16_t a)
+int16x1_t
+test_vqshluh_n_s16 (int16x1_t a)
 {
   return vqshluh_n_s16 (a, 4);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshlu\\ts\[0-9\]+" 1 } } */
 
-int32_t
-test_vqshlus_n_s32 (int32_t a)
+int32x1_t
+test_vqshlus_n_s32 (int32x1_t a)
 {
   return vqshlus_n_s32 (a, 5);
 }
@@ -1004,42 +1004,42 @@ test_vqshlud_n_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tsqshl\\tb\[0-9\]+" 2 } } */
 
-int8_t
-test_vqshlb_s8 (int8_t a, int8_t b)
+int8x1_t
+test_vqshlb_s8 (int8x1_t a, int8x1_t b)
 {
   return vqshlb_s8 (a, b);
 }
 
-int8_t
-test_vqshlb_n_s8 (int8_t a)
+int8x1_t
+test_vqshlb_n_s8 (int8x1_t a)
 {
   return vqshlb_n_s8 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshl\\th\[0-9\]+" 2 } } */
 
-int16_t
-test_vqshlh_s16 (int16_t a, int16_t b)
+int16x1_t
+test_vqshlh_s16 (int16x1_t a, int16x1_t b)
 {
   return vqshlh_s16 (a, b);
 }
 
-int16_t
-test_vqshlh_n_s16 (int16_t a)
+int16x1_t
+test_vqshlh_n_s16 (int16x1_t a)
 {
   return vqshlh_n_s16 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshl\\ts\[0-9\]+" 2 } } */
 
-int32_t
-test_vqshls_s32 (int32_t a, int32_t b)
+int32x1_t
+test_vqshls_s32 (int32x1_t a, int32x1_t b)
 {
   return vqshls_s32 (a, b);
 }
 
-int32_t
-test_vqshls_n_s32 (int32_t a)
+int32x1_t
+test_vqshls_n_s32 (int32x1_t a)
 {
   return vqshls_n_s32 (a, 4);
 }
@@ -1060,42 +1060,42 @@ test_vqshld_n_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tuqshl\\tb\[0-9\]+" 2 } } */
 
-uint8_t
-test_vqshlb_u8 (uint8_t a, uint8_t b)
+uint8x1_t
+test_vqshlb_u8 (uint8x1_t a, uint8x1_t b)
 {
   return vqshlb_u8 (a, b);
 }
 
-uint8_t
-test_vqshlb_n_u8 (uint8_t a)
+uint8x1_t
+test_vqshlb_n_u8 (uint8x1_t a)
 {
   return vqshlb_n_u8 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqshl\\th\[0-9\]+" 2 } } */
 
-uint16_t
-test_vqshlh_u16 (uint16_t a, uint16_t b)
+uint16x1_t
+test_vqshlh_u16 (uint16x1_t a, uint16x1_t b)
 {
   return vqshlh_u16 (a, b);
 }
 
-uint16_t
-test_vqshlh_n_u16 (uint16_t a)
+uint16x1_t
+test_vqshlh_n_u16 (uint16x1_t a)
 {
   return vqshlh_n_u16 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqshl\\ts\[0-9\]+" 2 } } */
 
-uint32_t
-test_vqshls_u32 (uint32_t a, uint32_t b)
+uint32x1_t
+test_vqshls_u32 (uint32x1_t a, uint32x1_t b)
 {
   return vqshls_u32 (a, b);
 }
 
-uint32_t
-test_vqshls_n_u32 (uint32_t a)
+uint32x1_t
+test_vqshls_n_u32 (uint32x1_t a)
 {
   return vqshls_n_u32 (a, 4);
 }
@@ -1116,23 +1116,23 @@ test_vqshld_n_u64 (uint64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tsqshrun\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqshrunh_n_s16 (int16_t a)
+int8x1_t
+test_vqshrunh_n_s16 (int16x1_t a)
 {
   return vqshrunh_n_s16 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshrun\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqshruns_n_s32 (int32_t a)
+int16x1_t
+test_vqshruns_n_s32 (int32x1_t a)
 {
   return vqshruns_n_s32 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshrun\\ts\[0-9\]+" 1 } } */
 
-int32_t
+int32x1_t
 test_vqshrund_n_s64 (int64x1_t a)
 {
   return vqshrund_n_s64 (a, 4);
@@ -1140,23 +1140,23 @@ test_vqshrund_n_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tsqrshrun\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqrshrunh_n_s16 (int16_t a)
+int8x1_t
+test_vqrshrunh_n_s16 (int16x1_t a)
 {
   return vqrshrunh_n_s16 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrshrun\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqrshruns_n_s32 (int32_t a)
+int16x1_t
+test_vqrshruns_n_s32 (int32x1_t a)
 {
   return vqrshruns_n_s32 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrshrun\\ts\[0-9\]+" 1 } } */
 
-int32_t
+int32x1_t
 test_vqrshrund_n_s64 (int64x1_t a)
 {
   return vqrshrund_n_s64 (a, 4);
@@ -1164,23 +1164,23 @@ test_vqrshrund_n_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tsqshrn\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqshrnh_n_s16 (int16_t a)
+int8x1_t
+test_vqshrnh_n_s16 (int16x1_t a)
 {
   return vqshrnh_n_s16 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshrn\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqshrns_n_s32 (int32_t a)
+int16x1_t
+test_vqshrns_n_s32 (int32x1_t a)
 {
   return vqshrns_n_s32 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqshrn\\ts\[0-9\]+" 1 } } */
 
-int32_t
+int32x1_t
 test_vqshrnd_n_s64 (int64x1_t a)
 {
   return vqshrnd_n_s64 (a, 4);
@@ -1188,23 +1188,23 @@ test_vqshrnd_n_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tuqshrn\\tb\[0-9\]+" 1 } } */
 
-uint8_t
-test_vqshrnh_n_u16 (uint16_t a)
+uint8x1_t
+test_vqshrnh_n_u16 (uint16x1_t a)
 {
   return vqshrnh_n_u16 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqshrn\\th\[0-9\]+" 1 } } */
 
-uint16_t
-test_vqshrns_n_u32 (uint32_t a)
+uint16x1_t
+test_vqshrns_n_u32 (uint32x1_t a)
 {
   return vqshrns_n_u32 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqshrn\\ts\[0-9\]+" 1 } } */
 
-uint32_t
+uint32x1_t
 test_vqshrnd_n_u64 (uint64x1_t a)
 {
   return vqshrnd_n_u64 (a, 4);
@@ -1212,23 +1212,23 @@ test_vqshrnd_n_u64 (uint64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tsqrshrn\\tb\[0-9\]+" 1 } } */
 
-int8_t
-test_vqrshrnh_n_s16 (int16_t a)
+int8x1_t
+test_vqrshrnh_n_s16 (int16x1_t a)
 {
   return vqrshrnh_n_s16 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrshrn\\th\[0-9\]+" 1 } } */
 
-int16_t
-test_vqrshrns_n_s32 (int32_t a)
+int16x1_t
+test_vqrshrns_n_s32 (int32x1_t a)
 {
   return vqrshrns_n_s32 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tsqrshrn\\ts\[0-9\]+" 1 } } */
 
-int32_t
+int32x1_t
 test_vqrshrnd_n_s64 (int64x1_t a)
 {
   return vqrshrnd_n_s64 (a, 4);
@@ -1236,23 +1236,23 @@ test_vqrshrnd_n_s64 (int64x1_t a)
 
 /* { dg-final { scan-assembler-times "\\tuqrshrn\\tb\[0-9\]+" 1 } } */
 
-uint8_t
-test_vqrshrnh_n_u16 (uint16_t a)
+uint8x1_t
+test_vqrshrnh_n_u16 (uint16x1_t a)
 {
   return vqrshrnh_n_u16 (a, 2);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqrshrn\\th\[0-9\]+" 1 } } */
 
-uint16_t
-test_vqrshrns_n_u32 (uint32_t a)
+uint16x1_t
+test_vqrshrns_n_u32 (uint32x1_t a)
 {
   return vqrshrns_n_u32 (a, 3);
 }
 
 /* { dg-final { scan-assembler-times "\\tuqrshrn\\ts\[0-9\]+" 1 } } */
 
-uint32_t
+uint32x1_t
 test_vqrshrnd_n_u64 (uint64x1_t a)
 {
   return vqrshrnd_n_u64 (a, 4);
Index: b/src/gcc/testsuite/gcc.target/aarch64/vqdmlslh_lane_s16.c
===================================================================
--- a/src/gcc/testsuite/gcc.target/aarch64/vqdmlslh_lane_s16.c
+++ b/src/gcc/testsuite/gcc.target/aarch64/vqdmlslh_lane_s16.c
@@ -5,8 +5,8 @@
 
 #include "arm_neon.h"
 
-int32_t
-t_vqdmlslh_lane_s16 (int32_t a, int16_t b, int16x4_t c)
+int32x1_t
+t_vqdmlslh_lane_s16 (int32x1_t a, int16x1_t b, int16x4_t c)
 {
   return vqdmlslh_lane_s16 (a, b, c, 0);
 }
Index: b/src/gcc/testsuite/ChangeLog
===================================================================
--- a/src/gcc/testsuite/ChangeLog
+++ b/src/gcc/testsuite/ChangeLog
@@ -3,18 +3,6 @@
 	PR ipa/61654
         * g++.dg/ipa/pr61654.C: New test.
 
-2014-09-11  Alan Lawrence  <alan.lawrence@arm.com>
-
-	Backport r214953 from mainline
-	2014-09-05  Alan Lawrence  <alan.lawrence@arm.com>
-
-	* gcc.target/aarch64/scalar_intrinsics.c (*): Replace all
-	int{32,16,8}x1_t with int{32,16,8}_t.
-	* gcc.target/aarch64/simd/vqdmlalh_lane_s16.c: Likewise.
-	* gcc.target/aarch64/simd/vqdmlslh_lane_s16.c: Likewise.
-	* gcc.target/aarch64/simd/vqdmullh_lane_s16.c: Likewise.
-	* gcc.target/aarch64/simd/vqdmulls_lane_s32.c: Likewise.
-
 2014-09-10  Xinliang David Li  <davidxl@google.com>
 
 	Backport from mainline
Index: b/src/gcc/config/aarch64/arm_neon.h
===================================================================
--- a/src/gcc/config/aarch64/arm_neon.h
+++ b/src/gcc/config/aarch64/arm_neon.h
@@ -39,6 +39,9 @@ typedef __builtin_aarch64_simd_hi int16x
 typedef __builtin_aarch64_simd_si int32x2_t
   __attribute__ ((__vector_size__ (8)));
 typedef int64_t int64x1_t;
+typedef int32_t int32x1_t;
+typedef int16_t int16x1_t;
+typedef int8_t int8x1_t;
 typedef double float64x1_t;
 typedef __builtin_aarch64_simd_sf float32x2_t
   __attribute__ ((__vector_size__ (8)));
@@ -53,6 +56,9 @@ typedef __builtin_aarch64_simd_uhi uint1
 typedef __builtin_aarch64_simd_usi uint32x2_t
   __attribute__ ((__vector_size__ (8)));
 typedef uint64_t uint64x1_t;
+typedef uint32_t uint32x1_t;
+typedef uint16_t uint16x1_t;
+typedef uint8_t uint8x1_t;
 typedef __builtin_aarch64_simd_qi int8x16_t
   __attribute__ ((__vector_size__ (16)));
 typedef __builtin_aarch64_simd_hi int16x8_t
@@ -8394,7 +8400,7 @@ vmul_n_u32 (uint32x2_t a, uint32_t b)
 #define vmull_high_lane_s16(a, b, c)                                    \
   __extension__                                                         \
     ({                                                                  \
-       int16x4_t b_ = (b);                                              \
+       int16x8_t b_ = (b);                                              \
        int16x8_t a_ = (a);                                              \
        int32x4_t result;                                                \
        __asm__ ("smull2 %0.4s, %1.8h, %2.h[%3]"                         \
@@ -8407,7 +8413,7 @@ vmul_n_u32 (uint32x2_t a, uint32_t b)
 #define vmull_high_lane_s32(a, b, c)                                    \
   __extension__                                                         \
     ({                                                                  \
-       int32x2_t b_ = (b);                                              \
+       int32x4_t b_ = (b);                                              \
        int32x4_t a_ = (a);                                              \
        int64x2_t result;                                                \
        __asm__ ("smull2 %0.2d, %1.4s, %2.s[%3]"                         \
@@ -8420,7 +8426,7 @@ vmul_n_u32 (uint32x2_t a, uint32_t b)
 #define vmull_high_lane_u16(a, b, c)                                    \
   __extension__                                                         \
     ({                                                                  \
-       uint16x4_t b_ = (b);                                             \
+       uint16x8_t b_ = (b);                                             \
        uint16x8_t a_ = (a);                                             \
        uint32x4_t result;                                               \
        __asm__ ("umull2 %0.4s, %1.8h, %2.h[%3]"                         \
@@ -8433,7 +8439,7 @@ vmul_n_u32 (uint32x2_t a, uint32_t b)
 #define vmull_high_lane_u32(a, b, c)                                    \
   __extension__                                                         \
     ({                                                                  \
-       uint32x2_t b_ = (b);                                             \
+       uint32x4_t b_ = (b);                                             \
        uint32x4_t a_ = (a);                                             \
        uint64x2_t result;                                               \
        __asm__ ("umull2 %0.2d, %1.4s, %2.s[%3]"                         \
@@ -20919,42 +20925,42 @@ vqabsq_s64 (int64x2_t __a)
   return (int64x2_t) __builtin_aarch64_sqabsv2di (__a);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqabsb_s8 (int8_t __a)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqabsb_s8 (int8x1_t __a)
 {
-  return (int8_t) __builtin_aarch64_sqabsqi (__a);
+  return (int8x1_t) __builtin_aarch64_sqabsqi (__a);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqabsh_s16 (int16_t __a)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqabsh_s16 (int16x1_t __a)
 {
-  return (int16_t) __builtin_aarch64_sqabshi (__a);
+  return (int16x1_t) __builtin_aarch64_sqabshi (__a);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqabss_s32 (int32_t __a)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqabss_s32 (int32x1_t __a)
 {
-  return (int32_t) __builtin_aarch64_sqabssi (__a);
+  return (int32x1_t) __builtin_aarch64_sqabssi (__a);
 }
 
 /* vqadd */
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqaddb_s8 (int8_t __a, int8_t __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqaddb_s8 (int8x1_t __a, int8x1_t __b)
 {
-  return (int8_t) __builtin_aarch64_sqaddqi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqaddqi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqaddh_s16 (int16_t __a, int16_t __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqaddh_s16 (int16x1_t __a, int16x1_t __b)
 {
-  return (int16_t) __builtin_aarch64_sqaddhi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqaddhi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqadds_s32 (int32_t __a, int32_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqadds_s32 (int32x1_t __a, int32x1_t __b)
 {
-  return (int32_t) __builtin_aarch64_sqaddsi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqaddsi (__a, __b);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
@@ -20963,22 +20969,22 @@ vqaddd_s64 (int64x1_t __a, int64x1_t __b
   return (int64x1_t) __builtin_aarch64_sqadddi (__a, __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqaddb_u8 (uint8_t __a, uint8_t __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqaddb_u8 (uint8x1_t __a, uint8x1_t __b)
 {
-  return (uint8_t) __builtin_aarch64_uqaddqi (__a, __b);
+  return (uint8x1_t) __builtin_aarch64_uqaddqi (__a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqaddh_u16 (uint16_t __a, uint16_t __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqaddh_u16 (uint16x1_t __a, uint16x1_t __b)
 {
-  return (uint16_t) __builtin_aarch64_uqaddhi (__a, __b);
+  return (uint16x1_t) __builtin_aarch64_uqaddhi (__a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
-vqadds_u32 (uint32_t __a, uint32_t __b)
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
+vqadds_u32 (uint32x1_t __a, uint32x1_t __b)
 {
-  return (uint32_t) __builtin_aarch64_uqaddsi (__a, __b);
+  return (uint32x1_t) __builtin_aarch64_uqaddsi (__a, __b);
 }
 
 __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))
@@ -21089,26 +21095,26 @@ vqdmlal_n_s32 (int64x2_t __a, int32x2_t
   return __builtin_aarch64_sqdmlal_nv2si (__a, __b, __c);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmlalh_s16 (int32_t __a, int16_t __b, int16_t __c)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmlalh_s16 (int32x1_t __a, int16x1_t __b, int16x1_t __c)
 {
   return __builtin_aarch64_sqdmlalhi (__a, __b, __c);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmlalh_lane_s16 (int32_t __a, int16_t __b, int16x4_t __c, const int __d)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmlalh_lane_s16 (int32x1_t __a, int16x1_t __b, int16x4_t __c, const int __d)
 {
   return __builtin_aarch64_sqdmlal_lanehi (__a, __b, __c, __d);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
-vqdmlals_s32 (int64x1_t __a, int32_t __b, int32_t __c)
+vqdmlals_s32 (int64x1_t __a, int32x1_t __b, int32x1_t __c)
 {
   return __builtin_aarch64_sqdmlalsi (__a, __b, __c);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
-vqdmlals_lane_s32 (int64x1_t __a, int32_t __b, int32x2_t __c, const int __d)
+vqdmlals_lane_s32 (int64x1_t __a, int32x1_t __b, int32x2_t __c, const int __d)
 {
   return __builtin_aarch64_sqdmlal_lanesi (__a, __b, __c, __d);
 }
@@ -21215,26 +21221,26 @@ vqdmlsl_n_s32 (int64x2_t __a, int32x2_t
   return __builtin_aarch64_sqdmlsl_nv2si (__a, __b, __c);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmlslh_s16 (int32_t __a, int16_t __b, int16_t __c)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmlslh_s16 (int32x1_t __a, int16x1_t __b, int16x1_t __c)
 {
   return __builtin_aarch64_sqdmlslhi (__a, __b, __c);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmlslh_lane_s16 (int32_t __a, int16_t __b, int16x4_t __c, const int __d)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmlslh_lane_s16 (int32x1_t __a, int16x1_t __b, int16x4_t __c, const int __d)
 {
   return __builtin_aarch64_sqdmlsl_lanehi (__a, __b, __c, __d);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
-vqdmlsls_s32 (int64x1_t __a, int32_t __b, int32_t __c)
+vqdmlsls_s32 (int64x1_t __a, int32x1_t __b, int32x1_t __c)
 {
   return __builtin_aarch64_sqdmlslsi (__a, __b, __c);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
-vqdmlsls_lane_s32 (int64x1_t __a, int32_t __b, int32x2_t __c, const int __d)
+vqdmlsls_lane_s32 (int64x1_t __a, int32x1_t __b, int32x2_t __c, const int __d)
 {
   return __builtin_aarch64_sqdmlsl_lanesi (__a, __b, __c, __d);
 }
@@ -21265,26 +21271,26 @@ vqdmulhq_lane_s32 (int32x4_t __a, int32x
   return __builtin_aarch64_sqdmulh_lanev4si (__a, __b, __c);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqdmulhh_s16 (int16_t __a, int16_t __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqdmulhh_s16 (int16x1_t __a, int16x1_t __b)
 {
-  return (int16_t) __builtin_aarch64_sqdmulhhi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqdmulhhi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqdmulhh_lane_s16 (int16_t __a, int16x4_t __b, const int __c)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqdmulhh_lane_s16 (int16x1_t __a, int16x4_t __b, const int __c)
 {
   return __builtin_aarch64_sqdmulh_lanehi (__a, __b, __c);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmulhs_s32 (int32_t __a, int32_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmulhs_s32 (int32x1_t __a, int32x1_t __b)
 {
-  return (int32_t) __builtin_aarch64_sqdmulhsi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqdmulhsi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmulhs_lane_s32 (int32_t __a, int32x2_t __b, const int __c)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmulhs_lane_s32 (int32x1_t __a, int32x2_t __b, const int __c)
 {
   return __builtin_aarch64_sqdmulh_lanesi (__a, __b, __c);
 }
@@ -21387,26 +21393,26 @@ vqdmull_n_s32 (int32x2_t __a, int32_t __
   return __builtin_aarch64_sqdmull_nv2si (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmullh_s16 (int16_t __a, int16_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmullh_s16 (int16x1_t __a, int16x1_t __b)
 {
-  return (int32_t) __builtin_aarch64_sqdmullhi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqdmullhi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqdmullh_lane_s16 (int16_t __a, int16x4_t __b, const int __c)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqdmullh_lane_s16 (int16x1_t __a, int16x4_t __b, const int __c)
 {
   return __builtin_aarch64_sqdmull_lanehi (__a, __b, __c);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
-vqdmulls_s32 (int32_t __a, int32_t __b)
+vqdmulls_s32 (int32x1_t __a, int32x1_t __b)
 {
   return (int64x1_t) __builtin_aarch64_sqdmullsi (__a, __b);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
-vqdmulls_lane_s32 (int32_t __a, int32x2_t __b, const int __c)
+vqdmulls_lane_s32 (int32x1_t __a, int32x2_t __b, const int __c)
 {
   return __builtin_aarch64_sqdmull_lanesi (__a, __b, __c);
 }
@@ -21449,40 +21455,40 @@ vqmovn_u64 (uint64x2_t __a)
   return (uint32x2_t) __builtin_aarch64_uqmovnv2di ((int64x2_t) __a);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqmovnh_s16 (int16_t __a)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqmovnh_s16 (int16x1_t __a)
 {
-  return (int8_t) __builtin_aarch64_sqmovnhi (__a);
+  return (int8x1_t) __builtin_aarch64_sqmovnhi (__a);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqmovns_s32 (int32_t __a)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqmovns_s32 (int32x1_t __a)
 {
-  return (int16_t) __builtin_aarch64_sqmovnsi (__a);
+  return (int16x1_t) __builtin_aarch64_sqmovnsi (__a);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
 vqmovnd_s64 (int64x1_t __a)
 {
-  return (int32_t) __builtin_aarch64_sqmovndi (__a);
+  return (int32x1_t) __builtin_aarch64_sqmovndi (__a);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqmovnh_u16 (uint16_t __a)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqmovnh_u16 (uint16x1_t __a)
 {
-  return (uint8_t) __builtin_aarch64_uqmovnhi (__a);
+  return (uint8x1_t) __builtin_aarch64_uqmovnhi (__a);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqmovns_u32 (uint32_t __a)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqmovns_u32 (uint32x1_t __a)
 {
-  return (uint16_t) __builtin_aarch64_uqmovnsi (__a);
+  return (uint16x1_t) __builtin_aarch64_uqmovnsi (__a);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
 vqmovnd_u64 (uint64x1_t __a)
 {
-  return (uint32_t) __builtin_aarch64_uqmovndi (__a);
+  return (uint32x1_t) __builtin_aarch64_uqmovndi (__a);
 }
 
 /* vqmovun */
@@ -21505,22 +21511,22 @@ vqmovun_s64 (int64x2_t __a)
   return (uint32x2_t) __builtin_aarch64_sqmovunv2di (__a);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqmovunh_s16 (int16_t __a)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqmovunh_s16 (int16x1_t __a)
 {
-  return (int8_t) __builtin_aarch64_sqmovunhi (__a);
+  return (int8x1_t) __builtin_aarch64_sqmovunhi (__a);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqmovuns_s32 (int32_t __a)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqmovuns_s32 (int32x1_t __a)
 {
-  return (int16_t) __builtin_aarch64_sqmovunsi (__a);
+  return (int16x1_t) __builtin_aarch64_sqmovunsi (__a);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
 vqmovund_s64 (int64x1_t __a)
 {
-  return (int32_t) __builtin_aarch64_sqmovundi (__a);
+  return (int32x1_t) __builtin_aarch64_sqmovundi (__a);
 }
 
 /* vqneg */
@@ -21531,22 +21537,22 @@ vqnegq_s64 (int64x2_t __a)
   return (int64x2_t) __builtin_aarch64_sqnegv2di (__a);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqnegb_s8 (int8_t __a)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqnegb_s8 (int8x1_t __a)
 {
-  return (int8_t) __builtin_aarch64_sqnegqi (__a);
+  return (int8x1_t) __builtin_aarch64_sqnegqi (__a);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqnegh_s16 (int16_t __a)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqnegh_s16 (int16x1_t __a)
 {
-  return (int16_t) __builtin_aarch64_sqneghi (__a);
+  return (int16x1_t) __builtin_aarch64_sqneghi (__a);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqnegs_s32 (int32_t __a)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqnegs_s32 (int32x1_t __a)
 {
-  return (int32_t) __builtin_aarch64_sqnegsi (__a);
+  return (int32x1_t) __builtin_aarch64_sqnegsi (__a);
 }
 
 /* vqrdmulh */
@@ -21575,26 +21581,26 @@ vqrdmulhq_lane_s32 (int32x4_t __a, int32
   return __builtin_aarch64_sqrdmulh_lanev4si (__a, __b, __c);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqrdmulhh_s16 (int16_t __a, int16_t __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqrdmulhh_s16 (int16x1_t __a, int16x1_t __b)
 {
-  return (int16_t) __builtin_aarch64_sqrdmulhhi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqrdmulhhi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqrdmulhh_lane_s16 (int16_t __a, int16x4_t __b, const int __c)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqrdmulhh_lane_s16 (int16x1_t __a, int16x4_t __b, const int __c)
 {
   return __builtin_aarch64_sqrdmulh_lanehi (__a, __b, __c);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqrdmulhs_s32 (int32_t __a, int32_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqrdmulhs_s32 (int32x1_t __a, int32x1_t __b)
 {
-  return (int32_t) __builtin_aarch64_sqrdmulhsi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqrdmulhsi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqrdmulhs_lane_s32 (int32_t __a, int32x2_t __b, const int __c)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqrdmulhs_lane_s32 (int32x1_t __a, int32x2_t __b, const int __c)
 {
   return __builtin_aarch64_sqrdmulh_lanesi (__a, __b, __c);
 }
@@ -21697,20 +21703,20 @@ vqrshlq_u64 (uint64x2_t __a, int64x2_t _
   return (uint64x2_t) __builtin_aarch64_uqrshlv2di ((int64x2_t) __a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqrshlb_s8 (int8_t __a, int8_t __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqrshlb_s8 (int8x1_t __a, int8x1_t __b)
 {
   return __builtin_aarch64_sqrshlqi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqrshlh_s16 (int16_t __a, int16_t __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqrshlh_s16 (int16x1_t __a, int16x1_t __b)
 {
   return __builtin_aarch64_sqrshlhi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqrshls_s32 (int32_t __a, int32_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqrshls_s32 (int32x1_t __a, int32x1_t __b)
 {
   return __builtin_aarch64_sqrshlsi (__a, __b);
 }
@@ -21721,22 +21727,22 @@ vqrshld_s64 (int64x1_t __a, int64x1_t __
   return __builtin_aarch64_sqrshldi (__a, __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqrshlb_u8 (uint8_t __a, uint8_t __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqrshlb_u8 (uint8x1_t __a, uint8x1_t __b)
 {
-  return (uint8_t) __builtin_aarch64_uqrshlqi (__a, __b);
+  return (uint8x1_t) __builtin_aarch64_uqrshlqi (__a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqrshlh_u16 (uint16_t __a, uint16_t __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqrshlh_u16 (uint16x1_t __a, uint16x1_t __b)
 {
-  return (uint16_t) __builtin_aarch64_uqrshlhi (__a, __b);
+  return (uint16x1_t) __builtin_aarch64_uqrshlhi (__a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
-vqrshls_u32 (uint32_t __a, uint32_t __b)
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
+vqrshls_u32 (uint32x1_t __a, uint32x1_t __b)
 {
-  return (uint32_t) __builtin_aarch64_uqrshlsi (__a, __b);
+  return (uint32x1_t) __builtin_aarch64_uqrshlsi (__a, __b);
 }
 
 __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))
@@ -21783,40 +21789,40 @@ vqrshrn_n_u64 (uint64x2_t __a, const int
   return (uint32x2_t) __builtin_aarch64_uqrshrn_nv2di ((int64x2_t) __a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqrshrnh_n_s16 (int16_t __a, const int __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqrshrnh_n_s16 (int16x1_t __a, const int __b)
 {
-  return (int8_t) __builtin_aarch64_sqrshrn_nhi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqrshrn_nhi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqrshrns_n_s32 (int32_t __a, const int __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqrshrns_n_s32 (int32x1_t __a, const int __b)
 {
-  return (int16_t) __builtin_aarch64_sqrshrn_nsi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqrshrn_nsi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
 vqrshrnd_n_s64 (int64x1_t __a, const int __b)
 {
-  return (int32_t) __builtin_aarch64_sqrshrn_ndi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqrshrn_ndi (__a, __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqrshrnh_n_u16 (uint16_t __a, const int __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqrshrnh_n_u16 (uint16x1_t __a, const int __b)
 {
-  return (uint8_t) __builtin_aarch64_uqrshrn_nhi (__a, __b);
+  return (uint8x1_t) __builtin_aarch64_uqrshrn_nhi (__a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqrshrns_n_u32 (uint32_t __a, const int __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqrshrns_n_u32 (uint32x1_t __a, const int __b)
 {
-  return (uint16_t) __builtin_aarch64_uqrshrn_nsi (__a, __b);
+  return (uint16x1_t) __builtin_aarch64_uqrshrn_nsi (__a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
 vqrshrnd_n_u64 (uint64x1_t __a, const int __b)
 {
-  return (uint32_t) __builtin_aarch64_uqrshrn_ndi (__a, __b);
+  return (uint32x1_t) __builtin_aarch64_uqrshrn_ndi (__a, __b);
 }
 
 /* vqrshrun */
@@ -21839,22 +21845,22 @@ vqrshrun_n_s64 (int64x2_t __a, const int
   return (uint32x2_t) __builtin_aarch64_sqrshrun_nv2di (__a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqrshrunh_n_s16 (int16_t __a, const int __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqrshrunh_n_s16 (int16x1_t __a, const int __b)
 {
-  return (int8_t) __builtin_aarch64_sqrshrun_nhi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqrshrun_nhi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqrshruns_n_s32 (int32_t __a, const int __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqrshruns_n_s32 (int32x1_t __a, const int __b)
 {
-  return (int16_t) __builtin_aarch64_sqrshrun_nsi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqrshrun_nsi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
 vqrshrund_n_s64 (int64x1_t __a, const int __b)
 {
-  return (int32_t) __builtin_aarch64_sqrshrun_ndi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqrshrun_ndi (__a, __b);
 }
 
 /* vqshl */
@@ -21955,20 +21961,20 @@ vqshlq_u64 (uint64x2_t __a, int64x2_t __
   return (uint64x2_t) __builtin_aarch64_uqshlv2di ((int64x2_t) __a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqshlb_s8 (int8_t __a, int8_t __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqshlb_s8 (int8x1_t __a, int8x1_t __b)
 {
   return __builtin_aarch64_sqshlqi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqshlh_s16 (int16_t __a, int16_t __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqshlh_s16 (int16x1_t __a, int16x1_t __b)
 {
   return __builtin_aarch64_sqshlhi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqshls_s32 (int32_t __a, int32_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqshls_s32 (int32x1_t __a, int32x1_t __b)
 {
   return __builtin_aarch64_sqshlsi (__a, __b);
 }
@@ -21979,22 +21985,22 @@ vqshld_s64 (int64x1_t __a, int64x1_t __b
   return __builtin_aarch64_sqshldi (__a, __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqshlb_u8 (uint8_t __a, uint8_t __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqshlb_u8 (uint8x1_t __a, uint8x1_t __b)
 {
-  return (uint8_t) __builtin_aarch64_uqshlqi (__a, __b);
+  return (uint8x1_t) __builtin_aarch64_uqshlqi (__a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqshlh_u16 (uint16_t __a, uint16_t __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqshlh_u16 (uint16x1_t __a, uint16x1_t __b)
 {
-  return (uint16_t) __builtin_aarch64_uqshlhi (__a, __b);
+  return (uint16x1_t) __builtin_aarch64_uqshlhi (__a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
-vqshls_u32 (uint32_t __a, uint32_t __b)
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
+vqshls_u32 (uint32x1_t __a, uint32x1_t __b)
 {
-  return (uint32_t) __builtin_aarch64_uqshlsi (__a, __b);
+  return (uint32x1_t) __builtin_aarch64_uqshlsi (__a, __b);
 }
 
 __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))
@@ -22099,22 +22105,22 @@ vqshlq_n_u64 (uint64x2_t __a, const int
   return (uint64x2_t) __builtin_aarch64_uqshl_nv2di ((int64x2_t) __a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqshlb_n_s8 (int8_t __a, const int __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqshlb_n_s8 (int8x1_t __a, const int __b)
 {
-  return (int8_t) __builtin_aarch64_sqshl_nqi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqshl_nqi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqshlh_n_s16 (int16_t __a, const int __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqshlh_n_s16 (int16x1_t __a, const int __b)
 {
-  return (int16_t) __builtin_aarch64_sqshl_nhi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqshl_nhi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqshls_n_s32 (int32_t __a, const int __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqshls_n_s32 (int32x1_t __a, const int __b)
 {
-  return (int32_t) __builtin_aarch64_sqshl_nsi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqshl_nsi (__a, __b);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
@@ -22123,22 +22129,22 @@ vqshld_n_s64 (int64x1_t __a, const int _
   return (int64x1_t) __builtin_aarch64_sqshl_ndi (__a, __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqshlb_n_u8 (uint8_t __a, const int __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqshlb_n_u8 (uint8x1_t __a, const int __b)
 {
-  return (uint8_t) __builtin_aarch64_uqshl_nqi (__a, __b);
+  return (uint8x1_t) __builtin_aarch64_uqshl_nqi (__a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqshlh_n_u16 (uint16_t __a, const int __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqshlh_n_u16 (uint16x1_t __a, const int __b)
 {
-  return (uint16_t) __builtin_aarch64_uqshl_nhi (__a, __b);
+  return (uint16x1_t) __builtin_aarch64_uqshl_nhi (__a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
-vqshls_n_u32 (uint32_t __a, const int __b)
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
+vqshls_n_u32 (uint32x1_t __a, const int __b)
 {
-  return (uint32_t) __builtin_aarch64_uqshl_nsi (__a, __b);
+  return (uint32x1_t) __builtin_aarch64_uqshl_nsi (__a, __b);
 }
 
 __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))
@@ -22197,22 +22203,22 @@ vqshluq_n_s64 (int64x2_t __a, const int
   return (uint64x2_t) __builtin_aarch64_sqshlu_nv2di (__a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqshlub_n_s8 (int8_t __a, const int __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqshlub_n_s8 (int8x1_t __a, const int __b)
 {
-  return (int8_t) __builtin_aarch64_sqshlu_nqi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqshlu_nqi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqshluh_n_s16 (int16_t __a, const int __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqshluh_n_s16 (int16x1_t __a, const int __b)
 {
-  return (int16_t) __builtin_aarch64_sqshlu_nhi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqshlu_nhi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqshlus_n_s32 (int32_t __a, const int __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqshlus_n_s32 (int32x1_t __a, const int __b)
 {
-  return (int32_t) __builtin_aarch64_sqshlu_nsi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqshlu_nsi (__a, __b);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
@@ -22259,40 +22265,40 @@ vqshrn_n_u64 (uint64x2_t __a, const int
   return (uint32x2_t) __builtin_aarch64_uqshrn_nv2di ((int64x2_t) __a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqshrnh_n_s16 (int16_t __a, const int __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqshrnh_n_s16 (int16x1_t __a, const int __b)
 {
-  return (int8_t) __builtin_aarch64_sqshrn_nhi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqshrn_nhi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqshrns_n_s32 (int32_t __a, const int __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqshrns_n_s32 (int32x1_t __a, const int __b)
 {
-  return (int16_t) __builtin_aarch64_sqshrn_nsi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqshrn_nsi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
 vqshrnd_n_s64 (int64x1_t __a, const int __b)
 {
-  return (int32_t) __builtin_aarch64_sqshrn_ndi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqshrn_ndi (__a, __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqshrnh_n_u16 (uint16_t __a, const int __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqshrnh_n_u16 (uint16x1_t __a, const int __b)
 {
-  return (uint8_t) __builtin_aarch64_uqshrn_nhi (__a, __b);
+  return (uint8x1_t) __builtin_aarch64_uqshrn_nhi (__a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqshrns_n_u32 (uint32_t __a, const int __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqshrns_n_u32 (uint32x1_t __a, const int __b)
 {
-  return (uint16_t) __builtin_aarch64_uqshrn_nsi (__a, __b);
+  return (uint16x1_t) __builtin_aarch64_uqshrn_nsi (__a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
 vqshrnd_n_u64 (uint64x1_t __a, const int __b)
 {
-  return (uint32_t) __builtin_aarch64_uqshrn_ndi (__a, __b);
+  return (uint32x1_t) __builtin_aarch64_uqshrn_ndi (__a, __b);
 }
 
 /* vqshrun */
@@ -22315,42 +22321,42 @@ vqshrun_n_s64 (int64x2_t __a, const int
   return (uint32x2_t) __builtin_aarch64_sqshrun_nv2di (__a, __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqshrunh_n_s16 (int16_t __a, const int __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqshrunh_n_s16 (int16x1_t __a, const int __b)
 {
-  return (int8_t) __builtin_aarch64_sqshrun_nhi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqshrun_nhi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqshruns_n_s32 (int32_t __a, const int __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqshruns_n_s32 (int32x1_t __a, const int __b)
 {
-  return (int16_t) __builtin_aarch64_sqshrun_nsi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqshrun_nsi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
 vqshrund_n_s64 (int64x1_t __a, const int __b)
 {
-  return (int32_t) __builtin_aarch64_sqshrun_ndi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqshrun_ndi (__a, __b);
 }
 
 /* vqsub */
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vqsubb_s8 (int8_t __a, int8_t __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vqsubb_s8 (int8x1_t __a, int8x1_t __b)
 {
-  return (int8_t) __builtin_aarch64_sqsubqi (__a, __b);
+  return (int8x1_t) __builtin_aarch64_sqsubqi (__a, __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vqsubh_s16 (int16_t __a, int16_t __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vqsubh_s16 (int16x1_t __a, int16x1_t __b)
 {
-  return (int16_t) __builtin_aarch64_sqsubhi (__a, __b);
+  return (int16x1_t) __builtin_aarch64_sqsubhi (__a, __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vqsubs_s32 (int32_t __a, int32_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vqsubs_s32 (int32x1_t __a, int32x1_t __b)
 {
-  return (int32_t) __builtin_aarch64_sqsubsi (__a, __b);
+  return (int32x1_t) __builtin_aarch64_sqsubsi (__a, __b);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
@@ -22359,22 +22365,22 @@ vqsubd_s64 (int64x1_t __a, int64x1_t __b
   return (int64x1_t) __builtin_aarch64_sqsubdi (__a, __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vqsubb_u8 (uint8_t __a, uint8_t __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vqsubb_u8 (uint8x1_t __a, uint8x1_t __b)
 {
-  return (uint8_t) __builtin_aarch64_uqsubqi (__a, __b);
+  return (uint8x1_t) __builtin_aarch64_uqsubqi (__a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vqsubh_u16 (uint16_t __a, uint16_t __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vqsubh_u16 (uint16x1_t __a, uint16x1_t __b)
 {
-  return (uint16_t) __builtin_aarch64_uqsubhi (__a, __b);
+  return (uint16x1_t) __builtin_aarch64_uqsubhi (__a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
-vqsubs_u32 (uint32_t __a, uint32_t __b)
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
+vqsubs_u32 (uint32x1_t __a, uint32x1_t __b)
 {
-  return (uint32_t) __builtin_aarch64_uqsubsi (__a, __b);
+  return (uint32x1_t) __builtin_aarch64_uqsubsi (__a, __b);
 }
 
 __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))
@@ -23590,22 +23596,22 @@ vsqaddq_u64 (uint64x2_t __a, int64x2_t _
 						    (int64x2_t) __b);
 }
 
-__extension__ static __inline uint8_t __attribute__ ((__always_inline__))
-vsqaddb_u8 (uint8_t __a, int8_t __b)
+__extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))
+vsqaddb_u8 (uint8x1_t __a, int8x1_t __b)
 {
-  return (uint8_t) __builtin_aarch64_usqaddqi ((int8_t) __a, __b);
+  return (uint8x1_t) __builtin_aarch64_usqaddqi ((int8x1_t) __a, __b);
 }
 
-__extension__ static __inline uint16_t __attribute__ ((__always_inline__))
-vsqaddh_u16 (uint16_t __a, int16_t __b)
+__extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))
+vsqaddh_u16 (uint16x1_t __a, int16x1_t __b)
 {
-  return (uint16_t) __builtin_aarch64_usqaddhi ((int16_t) __a, __b);
+  return (uint16x1_t) __builtin_aarch64_usqaddhi ((int16x1_t) __a, __b);
 }
 
-__extension__ static __inline uint32_t __attribute__ ((__always_inline__))
-vsqadds_u32 (uint32_t __a, int32_t __b)
+__extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))
+vsqadds_u32 (uint32x1_t __a, int32x1_t __b)
 {
-  return (uint32_t) __builtin_aarch64_usqaddsi ((int32_t) __a, __b);
+  return (uint32x1_t) __builtin_aarch64_usqaddsi ((int32x1_t) __a, __b);
 }
 
 __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))
@@ -25245,22 +25251,22 @@ vuqaddq_s64 (int64x2_t __a, uint64x2_t _
   return (int64x2_t) __builtin_aarch64_suqaddv2di (__a, (int64x2_t) __b);
 }
 
-__extension__ static __inline int8_t __attribute__ ((__always_inline__))
-vuqaddb_s8 (int8_t __a, uint8_t __b)
+__extension__ static __inline int8x1_t __attribute__ ((__always_inline__))
+vuqaddb_s8 (int8x1_t __a, uint8x1_t __b)
 {
-  return (int8_t) __builtin_aarch64_suqaddqi (__a, (int8_t) __b);
+  return (int8x1_t) __builtin_aarch64_suqaddqi (__a, (int8x1_t) __b);
 }
 
-__extension__ static __inline int16_t __attribute__ ((__always_inline__))
-vuqaddh_s16 (int16_t __a, uint16_t __b)
+__extension__ static __inline int16x1_t __attribute__ ((__always_inline__))
+vuqaddh_s16 (int16x1_t __a, uint16x1_t __b)
 {
-  return (int16_t) __builtin_aarch64_suqaddhi (__a, (int16_t) __b);
+  return (int16x1_t) __builtin_aarch64_suqaddhi (__a, (int16x1_t) __b);
 }
 
-__extension__ static __inline int32_t __attribute__ ((__always_inline__))
-vuqadds_s32 (int32_t __a, uint32_t __b)
+__extension__ static __inline int32x1_t __attribute__ ((__always_inline__))
+vuqadds_s32 (int32x1_t __a, uint32x1_t __b)
 {
-  return (int32_t) __builtin_aarch64_suqaddsi (__a, (int32_t) __b);
+  return (int32x1_t) __builtin_aarch64_suqaddsi (__a, (int32x1_t) __b);
 }
 
 __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))
Index: b/src/gcc/config/aarch64/aarch64.md
===================================================================
--- a/src/gcc/config/aarch64/aarch64.md
+++ b/src/gcc/config/aarch64/aarch64.md
@@ -1102,7 +1102,7 @@
   add\\t%x0, %x1, %x2
   sub\\t%x0, %x1, #%n2
   add\\t%d0, %d1, %d2"
-  [(set_attr "type" "alu_imm,alu_reg,alu_imm,neon_add")
+  [(set_attr "type" "alu_imm,alu_reg,alu_imm,alu_reg")
    (set_attr "simd" "*,*,*,yes")]
 )
 
